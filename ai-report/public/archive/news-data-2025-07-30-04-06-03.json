{
  "mainHeadline": {
    "text": "OpenAI is launching a version of ChatGPT for college students",
    "url": "https://www.technologyreview.com/2025/07/29/1120801/openai-is-launching-a-version-of-chatgpt-for-college-students/"
  },
  "topStories": [
    {
      "text": "Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues",
      "url": "https://arxiv.org/abs/2503.06424"
    },
    {
      "text": "ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs",
      "url": "https://arxiv.org/abs/2507.21083"
    },
    {
      "text": "A Survey on Memory-Efficient Transformer-Based Model Training in AI for Science",
      "url": "https://arxiv.org/abs/2501.11847"
    }
  ],
  "leftColumn": [
    {
      "text": "Adversarial attacks and defenses in explainable artificial intelligence: A survey",
      "url": "https://arxiv.org/abs/2306.06123"
    },
    {
      "text": "Comparative Analysis of Vision Transformers and Convolutional Neural Networks for Medical Image Classification",
      "url": "https://arxiv.org/abs/2507.21156"
    },
    {
      "text": "BREAKING MEMORY LIMITS: GRADIENT WAVELET TRANSFORM ENHANCES LLMS TRAINING",
      "url": "https://arxiv.org/abs/2501.07237"
    },
    {
      "text": "Privacy-Preserving AI for Encrypted Medical Imaging: A Framework for Secure Diagnosis and Learning",
      "url": "https://arxiv.org/abs/2507.21060"
    },
    {
      "text": "Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer",
      "url": "https://arxiv.org/abs/2507.00683"
    },
    {
      "text": "ChatGPT just got smarter: OpenAIâ€™s Study Mode helps students learn step-by-step",
      "url": "https://venturebeat.com/ai/chatgpt-just-got-smarter-openais-study-mode-helps-students-learn-step-by-step/"
    },
    {
      "text": "Ensuring Medical AI Safety: Interpretability-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data",
      "url": "https://arxiv.org/abs/2501.13818"
    },
    {
      "text": "LLM-Adapted Interpretation Framework for Machine Learning Models",
      "url": "https://arxiv.org/abs/2507.21179"
    }
  ],
  "centerColumn": [
    {
      "text": "Stochastic forest transition model dynamics and parameter estimation via deep learning",
      "url": "https://arxiv.org/abs/2507.21486"
    },
    {
      "text": "ChemDFM-R: An Chemical Reasoner LLM Enhanced with Atomized Chemical Knowledge",
      "url": "https://arxiv.org/abs/2507.21990"
    },
    {
      "text": "Compton Form Factor Extraction using Quantum Deep Neural Networks",
      "url": "https://arxiv.org/abs/2504.15458"
    },
    {
      "text": "HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs",
      "url": "https://arxiv.org/abs/2507.21815"
    },
    {
      "text": "Overview of ADoBo at IberLEF 2025: Automatic Detection of Anglicisms in Spanish",
      "url": "https://arxiv.org/abs/2507.21813"
    },
    {
      "text": "Can human clinical rationales improve the performance and explainability of clinical text classification models?",
      "url": "https://arxiv.org/abs/2507.21302"
    },
    {
      "text": "Riemannian Optimization on Tree Tensor Networks with Application in Machine Learning",
      "url": "https://arxiv.org/abs/2507.21726"
    },
    {
      "text": "Generalized few-shot transfer learning architecture for modeling the EDFA gain spectrum",
      "url": "https://arxiv.org/abs/2507.21728"
    }
  ],
  "rightColumn": [
    {
      "text": "Probing then Editing Response Personality of Large Language Models",
      "url": "https://arxiv.org/abs/2504.10227"
    },
    {
      "text": "Measuring Sample Quality with Copula Discrepancies",
      "url": "https://arxiv.org/abs/2507.21434"
    },
    {
      "text": "Cascading and Proxy Membership Inference Attacks",
      "url": "https://arxiv.org/abs/2507.21412"
    },
    {
      "text": "Image Captioning via Compact Bidirectional Architecture",
      "url": "https://arxiv.org/abs/2201.01984"
    },
    {
      "text": "Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning",
      "url": "https://arxiv.org/abs/2507.20906"
    },
    {
      "text": "CHIMERA: A Knowledge Base of Scientific Idea Recombinations for Research Analysis and Ideation",
      "url": "https://arxiv.org/abs/2505.20779"
    },
    {
      "text": "FrugalRAG: Learning to retrieve and reason for multi-hop QA",
      "url": "https://arxiv.org/abs/2507.07634"
    },
    {
      "text": "Reservoir Computation with Networks of Differentiating Neuron Ring Oscillators",
      "url": "https://arxiv.org/abs/2507.21377"
    }
  ],
  "lastUpdated": "2025-07-30T04:06:03Z"
}