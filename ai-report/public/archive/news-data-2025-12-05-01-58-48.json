{
  "mainHeadline": {
    "text": "Management of Substrate-Sensitive AI Capabilities (MoSSAIC) Part 2: Conflict",
    "url": "https://www.lesswrong.com/posts/biaCEzMQWZ6QapvSS/management-of-substrate-sensitive-ai-capabilities-mossaic-2"
  },
  "topStories": [
    {
      "text": "Anthropic vs. OpenAI red teaming methods reveal different security priorities for enterprise AI",
      "url": "https://venturebeat.com/security/anthropic-vs-openai-red-teaming-methods-reveal-different-security-priorities"
    },
    {
      "text": "Will misaligned AIs know that they're misaligned?",
      "url": "https://www.lesswrong.com/posts/5izg4P9h6HgX9X3AE/will-misaligned-ais-know-that-they-re-misaligned"
    },
    {
      "text": "GAM takes aim at “context rot”: A dual-agent memory architecture that outperforms long-context LLMs",
      "url": "https://venturebeat.com/ai/gam-takes-aim-at-context-rot-a-dual-agent-memory-architecture-that",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/MI0B0KoyfgsNsPcZnfzUu/8de4abaf5670a0d41b186dd175236986/Memory.png?w=300\u0026q=30",
        "alt": "GAM takes aim at “context rot”: A dual-agent memory architecture that outperforms long-context LLMs",
        "width": 600,
        "height": 400
      }
    }
  ],
  "leftColumn": [
    {
      "text": "The 'truth serum' for AI: OpenAI’s new method for training models to confess their mistakes",
      "url": "https://venturebeat.com/ai/the-truth-serum-for-ai-openais-new-method-for-training-models-to-confess"
    },
    {
      "text": "The behavioral selection model for predicting AI motivations",
      "url": "https://www.lesswrong.com/posts/FeaJcWkC6fuRAMsfp/the-behavioral-selection-model-for-predicting-ai-motivations-1"
    },
    {
      "text": "OPENAI HAS TRAINED ITS LLM TO CONFESS TO BAD BEHAVIOR",
      "url": "https://www.technologyreview.com/2025/12/03/1128740/openai-has-trained-its-llm-to-confess-to-bad-behavior/"
    },
    {
      "text": "Try Training SAEs with RLAIF",
      "url": "https://www.lesswrong.com/posts/DKAqtetYmjeKZJHPw/try-training-saes-with-rlaif"
    },
    {
      "text": "Cross Layer Transcoders for the Qwen3 LLM Family",
      "url": "https://www.lesswrong.com/posts/cW9AdDm2DZtbXBnvt/cross-layer-transcoders-for-the-qwen3-llm-family"
    },
    {
      "text": "AWS launches Kiro powers with Stripe, Figma, and Datadog integrations for AI-assisted coding",
      "url": "https://venturebeat.com/ai/aws-launches-kiro-powers-with-stripe-figma-and-datadog-integrations-for-ai"
    },
    {
      "text": "Sydney AI Safety Fellowship 2026 (Priority deadline this Sunday)",
      "url": "https://www.alignmentforum.org/posts/RvzrwrtbA7NfeXgDx/sydney-ai-safety-fellowship-2026-priority-deadline-this"
    },
    {
      "text": "An Abstract Arsenal: Future Tokens in Claude Skills",
      "url": "https://www.lesswrong.com/posts/SBjcKqaEZatZqSXrM/an-abstract-arsenal-future-tokens-in-claude-skills"
    }
  ],
  "centerColumn": [
    {
      "text": "BlurDM: A Blur Diffusion Model for Image Deblurring",
      "url": "https://arxiv.org/abs/2512.03979"
    },
    {
      "text": "Real-Time Procedural Learning From Experience for AI Agents",
      "url": "https://arxiv.org/abs/2511.22074"
    },
    {
      "text": "6 reasons why “alignment-is-hard” discourse seems alien to human intuitions, and vice-versa",
      "url": "https://www.alignmentforum.org/posts/d4HNRdw6z7Xqbnu5E/6-reasons-why-alignment-is-hard-discourse-seems-alien-to"
    },
    {
      "text": "The Download: AI and coding, and Waymo’s aggressive driverless cars",
      "url": "https://www.technologyreview.com/2025/12/03/1128724/the-download-ai-and-coding-and-waymos-aggressive-driverless-cars/"
    },
    {
      "text": "Text a community college librarian",
      "url": "https://simonwillison.net/2025/Dec/4/text-a-librarian/#atom-everything"
    },
    {
      "text": "Google’s AI model is getting really good at spoofing phone photos",
      "url": "https://www.theverge.com/report/837971/google-nano-banana-pro-realistic-phone-photos"
    },
    {
      "text": "Do Labels Make AI Blind? Self-Supervision Solves the Age-Old Binding Problem",
      "url": "https://towardsdatascience.com/emergent-object-binding-from-self-supervised-not-supervised-learning/"
    },
    {
      "text": "AI chatbots can be wooed into crimes with poetry",
      "url": "https://www.theverge.com/report/838167/ai-chatbots-can-be-wooed-into-crimes-with-poetry"
    }
  ],
  "rightColumn": [
    {
      "text": "Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs",
      "url": "https://arxiv.org/abs/2503.03428"
    },
    {
      "text": "Learning Steerable Clarification Policies with Collaborative Self-play",
      "url": "https://arxiv.org/abs/2512.04068"
    },
    {
      "text": "Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting",
      "url": "https://arxiv.org/abs/2506.23888"
    },
    {
      "text": "Are you a robot? Detecting Autonomous Vehicles from Behavior Analysis",
      "url": "https://arxiv.org/abs/2403.09571"
    },
    {
      "text": "ConfRover: Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression",
      "url": "https://arxiv.org/abs/2505.17478"
    },
    {
      "text": "E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing",
      "url": "https://arxiv.org/abs/2512.03109"
    },
    {
      "text": "PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation",
      "url": "https://arxiv.org/abs/2512.03848"
    },
    {
      "text": "SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models",
      "url": "https://arxiv.org/abs/2506.00821"
    }
  ],
  "lastUpdated": "2025-12-05T01:58:48Z"
}