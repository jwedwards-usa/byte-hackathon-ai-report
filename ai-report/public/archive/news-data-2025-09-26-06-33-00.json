{
  "mainHeadline": {
    "text": "AI #135: OPENAI SHOWS US THE MONEY",
    "url": "https://www.lesswrong.com/posts/P5ZuoCwGCZyecBxeN/ai-135-openai-shows-us-the-money"
  },
  "topStories": [
    {
      "text": "Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text",
      "url": "https://arxiv.org/abs/2509.20375"
    },
    {
      "text": "WHAT GPT-OSS LEAKS ABOUT\nOPENAI'S TRAINING DATA",
      "url": "https://www.lesswrong.com/posts/iY9584TRhqrzawhZg/what-gpt-oss-leaks-about-openai-s-training-data"
    },
    {
      "text": "OpenAI really, really wants you to start your day with ChatGPT Pulse",
      "url": "https://www.theverge.com/ai-artificial-intelligence/785881/openai-really-really-wants-you-to-start-your-day-with-chatgpt-pulse"
    }
  ],
  "leftColumn": [
    {
      "text": "Constrained Belief Updates and Geometric Structures in Transformer Representations for the RRXOR Process",
      "url": "https://www.lesswrong.com/posts/BRiQ6Mn5HKc5SoyY3/constrained-belief-updates-and-geometric-structures-in"
    },
    {
      "text": "BREAKING THE EXPLORATION BOTTLENECK: RUBRIC-SCAFFOLDED REINFORCEMENT LEARNING FOR GENERAL LLM REASONING",
      "url": "https://arxiv.org/abs/2508.16949"
    },
    {
      "text": "Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis",
      "url": "https://arxiv.org/abs/2509.20768"
    },
    {
      "text": "CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain",
      "url": "https://arxiv.org/abs/2509.19925"
    },
    {
      "text": "Embodied AI: From LLMs to World Models",
      "url": "https://arxiv.org/abs/2509.20021"
    },
    {
      "text": "Widening AI Safety's talent pipeline by meeting people where they are",
      "url": "https://www.lesswrong.com/posts/x6ffKSHXxxbueYrHE/widening-ai-safety-s-talent-pipeline-by-meeting-people-where"
    },
    {
      "text": "Copycats: the many lives of a publicly available medical imaging dataset",
      "url": "https://arxiv.org/abs/2402.06353"
    },
    {
      "text": "STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation",
      "url": "https://arxiv.org/abs/2509.20190"
    }
  ],
  "centerColumn": [
    {
      "text": "Building Tailored Speech Recognizers for Japanese Speaking Assessment",
      "url": "https://arxiv.org/abs/2509.20655"
    },
    {
      "text": "Constrained Decoding for Robotics Foundation Models",
      "url": "https://arxiv.org/abs/2509.01728"
    },
    {
      "text": "RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing",
      "url": "https://arxiv.org/abs/2506.03880"
    },
    {
      "text": "Learning Ising Models under Hard Constraints using One Sample",
      "url": "https://arxiv.org/abs/2509.20993"
    },
    {
      "text": "Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces",
      "url": "https://arxiv.org/abs/2509.19403"
    },
    {
      "text": "Synthetic bootstrapped pretraining",
      "url": "https://arxiv.org/abs/2509.15248"
    },
    {
      "text": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation",
      "url": "https://arxiv.org/abs/2506.04251"
    },
    {
      "text": "Learning Conformal Explainers for Image Classifiers",
      "url": "https://arxiv.org/abs/2509.21209"
    }
  ],
  "rightColumn": [
    {
      "text": "Personalized Federated Dictionary Learning for Modeling Heterogeneity in Multi-site fMRI Data",
      "url": "https://arxiv.org/abs/2509.20627"
    },
    {
      "text": "Latent Twins",
      "url": "https://arxiv.org/abs/2509.20615"
    },
    {
      "text": "Policy Compatible Skill Incremental Learning via Lazy Learning Interface",
      "url": "https://arxiv.org/abs/2509.20612"
    },
    {
      "text": "LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition",
      "url": "https://arxiv.org/abs/2509.19330"
    },
    {
      "text": "MMG: Mutual Information Estimation via the MMSE Gap in Diffusion",
      "url": "https://arxiv.org/abs/2509.20609"
    },
    {
      "text": "Quantifying Compositionality of Classic and State-of-the-Art Embeddings",
      "url": "https://arxiv.org/abs/2509.19332"
    },
    {
      "text": "Pluralistic Off-policy Evaluation and Alignment",
      "url": "https://arxiv.org/abs/2509.19333"
    },
    {
      "text": "Bit is all we need: binary normalized neural networks",
      "url": "https://arxiv.org/abs/2509.07025"
    }
  ],
  "lastUpdated": "2025-09-26T06:33:00Z"
}