{
  "mainHeadline": {
    "text": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Unveiling AI's Potential Through Tools, Techniques, and Applications",
    "url": "https://arxiv.org/abs/2410.01268"
  },
  "topStories": [
    {
      "text": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Handy Appetizer",
      "url": "https://arxiv.org/abs/2409.17120"
    },
    {
      "text": "Anthropic's Claude Code can now read your Slack messages and write code for you",
      "url": "https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for"
    },
    {
      "text": "Z.ai debuts open source GLM-4.6V, a native tool-calling vision model for multimodal reasoning",
      "url": "https://venturebeat.com/ai/z-ai-debuts-open-source-glm-4-6v-a-native-tool-calling-vision-model-for"
    }
  ],
  "leftColumn": [
    {
      "text": "OpenAI says it’s disabled ad-like app promotions in ChatGPT",
      "url": "https://www.theverge.com/news/839882/openai-chatgpt-ads-app-promo-messages-turned-off"
    },
    {
      "text": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety",
      "url": "https://arxiv.org/abs/2507.11473"
    },
    {
      "text": "Artificial Intelligence, Machine Learning, Deep Learning, and Generative AI — Clearly Explained",
      "url": "https://towardsdatascience.com/artificial-intelligence-machine-learning-deep-learning-and-generative-ai-clearly-explained/"
    },
    {
      "text": "Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education",
      "url": "https://arxiv.org/abs/2512.05167"
    },
    {
      "text": "HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization",
      "url": "https://arxiv.org/abs/2503.04598"
    },
    {
      "text": "Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images",
      "url": "https://arxiv.org/abs/2506.06389"
    },
    {
      "text": "ARC-AGI Without Pretraining",
      "url": "https://arxiv.org/abs/2512.06104"
    },
    {
      "text": "Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning",
      "url": "https://arxiv.org/abs/2507.16302"
    }
  ],
  "centerColumn": [
    {
      "text": "Canonical Tail Dependence for Soft Extremal Clustering of Multichannel Brain Signals",
      "url": "https://arxiv.org/abs/2512.06435"
    },
    {
      "text": "Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization",
      "url": "https://arxiv.org/abs/2512.07478"
    },
    {
      "text": "Small Language Models Reshape Higher Education: Courses, Textbooks, and Teaching",
      "url": "https://arxiv.org/abs/2512.06001"
    },
    {
      "text": "Training Language Models to Use Prolog as a Tool",
      "url": "https://arxiv.org/abs/2512.07407"
    },
    {
      "text": "Investigating Training and Generalization in Faithful Self-Explanations of Large Language Models",
      "url": "https://arxiv.org/abs/2512.07288"
    },
    {
      "text": "Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data",
      "url": "https://arxiv.org/abs/2512.07277"
    },
    {
      "text": "Trusted AI Agents in the Cloud",
      "url": "https://arxiv.org/abs/2512.05951"
    },
    {
      "text": "Enhanced Spatiotemporal Consistency for Image-to-LiDAR Data Pretraining",
      "url": "https://arxiv.org/abs/2503.19912"
    }
  ],
  "rightColumn": [
    {
      "text": "Do Large Language Models Truly Understand Cross-cultural Differences?",
      "url": "https://arxiv.org/abs/2512.07075"
    },
    {
      "text": "Countering Overfitting with Counterfactual Examples",
      "url": "https://arxiv.org/abs/2502.09193"
    },
    {
      "text": "EasySpec: Layer-Parallel Speculative Decoding for Efficient Multi-GPU Utilization",
      "url": "https://arxiv.org/abs/2502.02493"
    },
    {
      "text": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization",
      "url": "https://arxiv.org/abs/2506.13771"
    },
    {
      "text": "FVA-RAG: Falsification-Verification Alignment for Mitigating Sycophantic Hallucinations",
      "url": "https://arxiv.org/abs/2512.07015"
    },
    {
      "text": "Progress Ratio Embeddings: An Impatience Signal for Robust Length Control in Neural Text Generation",
      "url": "https://arxiv.org/abs/2512.06938"
    },
    {
      "text": "VERIRAG: A Post-Retrieval Auditing of Scientific Study Summaries",
      "url": "https://arxiv.org/abs/2507.17948"
    },
    {
      "text": "Automated PRO-CTCAE Symptom Selection based on Prior Adverse Event Profiles",
      "url": "https://arxiv.org/abs/2512.06919"
    }
  ],
  "lastUpdated": "2025-12-09T06:41:07Z"
}