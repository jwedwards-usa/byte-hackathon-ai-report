{
  "mainHeadline": {
    "text": "OPENAI’S GPT-OSS IS ALREADY OLD NEWS",
    "url": "https://www.lesswrong.com/posts/AJ94X73M6KgAZFJH2/openai-s-gpt-oss-is-already-old-news"
  },
  "topStories": [
    {
      "text": "CHATGPT IS THE DAGUERREOTYPE OF AI",
      "url": "https://www.lesswrong.com/posts/mw4HtmQRQ4DAucxEj/chatgpt-is-the-daguerreotype-of-ai"
    },
    {
      "text": "ChatGPT users dismayed as OpenAI pulls popular models GPT-4o, o3 and more — enterprise API remains (for now)",
      "url": "https://venturebeat.com/ai/chatgpt-users-dismayed-as-openai-pulls-popular-models-gpt-4o-o3-and-more-enterprise-api-remains-for-now/"
    },
    {
      "text": "THE DOWNLOAD: GPT-5 IS HERE, AND INTEL’S CEO DRAMA",
      "url": "https://www.technologyreview.com/2025/08/08/1121330/the-download-gpt-5-is-here-and-intels-ceo-drama/"
    }
  ],
  "leftColumn": [
    {
      "text": "Claude, GPT, and Gemini All Struggle to Evade Monitors",
      "url": "https://www.alignmentforum.org/posts/dwEgSEPxpKjz3Fw5k/claude-gpt-and-gemini-all-struggle-to-evade-monitors"
    },
    {
      "text": "WE’RE TESTING A NEW, AI-POWERED GOOGLE FINANCE.",
      "url": "https://blog.google/products/search/google-finance-ai/"
    },
    {
      "text": "Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini",
      "url": "https://arxiv.org/abs/2508.04820"
    },
    {
      "text": "PREVIEWING GPT-5 AT OPENAI'S OFFICE",
      "url": "https://simonwillison.net/2025/Aug/7/previewing-gpt-5/#atom-everything"
    },
    {
      "text": "OpenAI launches GPT-5, nano, mini and Pro — not AGI, but capable of generating ‘software-on-demand’",
      "url": "https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand/"
    },
    {
      "text": "Preface to \"Simulacra and Simulation: Selections from the Work of Janus\"",
      "url": "https://www.lesswrong.com/posts/5EJQGYvohJpvEZwKd/preface-to-simulacra-and-simulation-selections-from-the-work"
    },
    {
      "text": "ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs",
      "url": "https://arxiv.org/abs/2508.05282"
    },
    {
      "text": "Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates",
      "url": "https://arxiv.org/abs/2508.04886"
    }
  ],
  "centerColumn": [
    {
      "text": "Probabilities of Chat LLMs Are Miscalibrated but Still Predict Correctness on Multiple-Choice Q\u0026A",
      "url": "https://arxiv.org/abs/2402.13213"
    },
    {
      "text": "Systolic Array-based Accelerator for Structured State-Space Models",
      "url": "https://arxiv.org/abs/2507.21394"
    },
    {
      "text": "BOASF: A Unified Framework for Speeding up Automatic Machine Learning via Adaptive Successive Filtering",
      "url": "https://arxiv.org/abs/2507.20446"
    },
    {
      "text": "When in Doubt, Cascade: Towards Building Efficient and Capable Guardrails",
      "url": "https://arxiv.org/abs/2407.06323"
    },
    {
      "text": "Explainable Evidential Clustering",
      "url": "https://arxiv.org/abs/2507.12192"
    },
    {
      "text": "A Structure-Preserving Framework for Solving Parabolic Partial Differential Equations with Neural Networks",
      "url": "https://arxiv.org/abs/2504.10273"
    },
    {
      "text": "Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision",
      "url": "https://arxiv.org/abs/2508.05606"
    },
    {
      "text": "Getting out of the Big-Muddy: Escalation of Commitment in LLMs",
      "url": "https://arxiv.org/abs/2508.01545"
    }
  ],
  "rightColumn": [
    {
      "text": "Nonasymptotic Analysis of Stochastic Gradient Descent with the Richardson-Romberg Extrapolation",
      "url": "https://arxiv.org/abs/2410.05106"
    },
    {
      "text": "InfoQ: Mixed-Precision Quantization via Global Information Flow",
      "url": "https://arxiv.org/abs/2508.04753"
    },
    {
      "text": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
      "url": "https://arxiv.org/abs/2412.03930"
    },
    {
      "text": "A Foundational Multi-Modal Model for Few-Shot Learning",
      "url": "https://arxiv.org/abs/2508.04746"
    },
    {
      "text": "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation",
      "url": "https://arxiv.org/abs/2412.03069"
    },
    {
      "text": "Parameter-free entropy-regularized multi-view clustering with hierarchical feature selection",
      "url": "https://arxiv.org/abs/2508.05504"
    },
    {
      "text": "From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging",
      "url": "https://arxiv.org/abs/2410.01215"
    },
    {
      "text": "CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation",
      "url": "https://arxiv.org/abs/2409.02098"
    }
  ],
  "lastUpdated": "2025-08-08T12:53:49Z"
}