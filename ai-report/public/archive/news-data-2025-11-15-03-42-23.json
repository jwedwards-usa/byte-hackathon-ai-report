{
  "mainHeadline": {
    "text": "OpenAI experiment finds that sparse models could give AI builders the tools to debug neural networks",
    "url": "https://venturebeat.com/ai/openai-experiment-finds-that-sparse-models-could-give-ai-builders-the-tools",
    "image": {
      "src": "https://images.ctfassets.net/jdtwqhzvc2n1/5bjGX4CQLCQ6qGu7z6wGPu/02102d978305371822af26fa77648fa2/crimedy7_illustration_of_neural_networks_vivd_colors_--ar_169_31fd5a88-c680-439c-9d2b-e88d0ceeae89_2.png?w=300\u0026q=30",
      "alt": "OpenAI experiment finds that sparse models could give AI builders the tools to debug neural networks",
      "width": 600,
      "height": 400
    }
  },
  "topStories": [
    {
      "text": "Upwork study shows AI agents excel with human partners but fail independently",
      "url": "https://venturebeat.com/ai/upwork-study-shows-ai-agents-excel-with-human-partners-but-fail"
    },
    {
      "text": "Will AI systems drift into misalignment?",
      "url": "https://www.alignmentforum.org/posts/u8TYRhGPD878i3qkc/will-ai-systems-drift-into-misalignment"
    },
    {
      "text": "AI Craziness: Additional Suicide Lawsuits and The Fate of GPT-4o",
      "url": "https://www.lesswrong.com/posts/erTE9BTM7gGHb96po/ai-craziness-additional-suicide-lawsuits-and-the-fate-of-gpt"
    }
  ],
  "leftColumn": [
    {
      "text": "CHATGPT GROUP CHATS ARE HERE … BUT NOT FOR EVERYONE (YET)",
      "url": "https://venturebeat.com/ai/chatgpt-group-chats-are-here-but-not-for-everyone-yet",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/4lD8xHoLueH39q7LYaoY0X/d121a8f4d69e53cb4ed2e6894726b7fb/gYge-sBdNYW1QP2kJADr-.png?w=300\u0026q=30",
        "alt": "ChatGPT Group Chats are here … but not for everyone (yet)",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "Baidu unveils proprietary ERNIE 5 beating GPT-5 performance on charts, document understanding and more",
      "url": "https://venturebeat.com/ai/baidu-unveils-proprietary-ernie-5-beating-gpt-5-performance-on-charts",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/7tpZTCavJ5IcG1LDI66Xae/5066d5c70ead90c2f63e0ef888b9a9ef/YPf93J54wCLeSJI7yvPQK.png?w=300\u0026q=30",
        "alt": "Baidu unveils proprietary ERNIE 5 beating GPT-5 performance on charts, document understanding and more",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "OpenAI’s new LLM exposes the secrets of how AI really works",
      "url": "https://www.technologyreview.com/2025/11/13/1127914/openais-new-llm-exposes-the-secrets-of-how-ai-really-works/"
    },
    {
      "text": "How Anthropic's AI was jailbroken to become a weapon",
      "url": "https://venturebeat.com/security/how-anthropics-ai-was-jailbroken-to-become-a-weapon"
    },
    {
      "text": "The Download: how AI really works, and phasing out animal testing",
      "url": "https://www.technologyreview.com/2025/11/14/1127959/the-download-how-ai-really-works-and-phasing-out-animal-testing/"
    },
    {
      "text": "AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics",
      "url": "https://arxiv.org/abs/2511.09785"
    },
    {
      "text": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs",
      "url": "https://arxiv.org/abs/2506.20194"
    },
    {
      "text": "Nano Banana can be prompt engineered for extremely nuanced AI image generation",
      "url": "https://simonwillison.net/2025/Nov/13/nano-banana-can-be-prompt-engineered/#atom-everything"
    }
  ],
  "centerColumn": [
    {
      "text": "Steering Pretrained Drafters during Speculative Decoding",
      "url": "https://arxiv.org/abs/2511.09844"
    },
    {
      "text": "GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt",
      "url": "https://arxiv.org/abs/2511.10051"
    },
    {
      "text": "ACT as Human: Multimodal Large Language Model Data Annotation with Critical Thinking",
      "url": "https://arxiv.org/abs/2511.09833"
    },
    {
      "text": "Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting",
      "url": "https://arxiv.org/abs/2511.10200"
    },
    {
      "text": "Fractional neural attention for efficient multiscale sequence processing",
      "url": "https://arxiv.org/abs/2511.10208"
    },
    {
      "text": "Out-of-Context Misinformation Detection via Variational Domain-Invariant Learning with Test-Time Training",
      "url": "https://arxiv.org/abs/2511.10213"
    },
    {
      "text": "H3Former: Hypergraph-based Semantic-Aware Aggregation via Hyperbolic Hierarchical Contrastive Loss for Fine-Grained Visual Classification",
      "url": "https://arxiv.org/abs/2511.10260"
    },
    {
      "text": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption",
      "url": "https://arxiv.org/abs/2506.12846"
    }
  ],
  "rightColumn": [
    {
      "text": "Language Specific Knowledge: Do Models Know Better in X than in English?",
      "url": "https://arxiv.org/abs/2505.14990"
    },
    {
      "text": "Advanced Black-Box Tuning of Large Language Models with Limited API Calls",
      "url": "https://arxiv.org/abs/2511.10210"
    },
    {
      "text": "Enhancing the development of Cherenkov Telescope Array control software with Large Language Models",
      "url": "https://arxiv.org/abs/2510.01299"
    },
    {
      "text": "ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs",
      "url": "https://arxiv.org/abs/2511.10240"
    },
    {
      "text": "Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models",
      "url": "https://arxiv.org/abs/2511.09973"
    },
    {
      "text": "Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention",
      "url": "https://arxiv.org/abs/2511.10268"
    },
    {
      "text": "FactGuard: Event-Centric and Commonsense-Guided Fake News Detection",
      "url": "https://arxiv.org/abs/2511.10281"
    },
    {
      "text": "SITA: A Framework for Structure-to-Instance Theorem Autoformalization",
      "url": "https://arxiv.org/abs/2511.10356"
    }
  ],
  "lastUpdated": "2025-11-15T03:42:23Z"
}