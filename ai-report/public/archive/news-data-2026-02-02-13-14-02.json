{
  "mainHeadline": {
    "text": "Lost in Transmission: When and Why LLMs Fail to Reason Globally",
    "url": "https://arxiv.org/abs/2505.08140"
  },
  "topStories": [
    {
      "text": "A SYSTEMATIC LITERATURE REVIEW ON LLM DEFENSES AGAINST PROMPT INJECTION AND JAILBREAKING: EXPANDING NIST TAXONOMY",
      "url": "https://arxiv.org/abs/2601.22240"
    },
    {
      "text": "SYMMETRY BREAKING IN TRANSFORMERS FOR EFFICIENT AND INTERPRETABLE TRAINING",
      "url": "https://arxiv.org/abs/2601.22257"
    },
    {
      "text": "Qualitative Evaluation of LLM-Designed GUI",
      "url": "https://arxiv.org/abs/2601.22759"
    }
  ],
  "leftColumn": [
    {
      "text": "AI Kill Switch for malicious web-based LLM agent",
      "url": "https://arxiv.org/abs/2511.13725"
    },
    {
      "text": "Evaluating LLMs for Career Guidance: Comparative Analysis of Computing Competency Recommendations Across Ten African Countries",
      "url": "https://arxiv.org/abs/2510.18902"
    },
    {
      "text": "Moltbook and the AI Alignment Problem",
      "url": "https://www.lesswrong.com/posts/BKW3AZDTQdv7TiKCA/moltbook-and-the-ai-alignment-problem"
    },
    {
      "text": "LLMs Explain't: A Post-Mortem on Semantic Interpretability in Transformer Models",
      "url": "https://arxiv.org/abs/2601.22928"
    },
    {
      "text": "Pretrained Battery Transformer (PBT): A battery life prediction foundation model",
      "url": "https://arxiv.org/abs/2512.16334"
    },
    {
      "text": "Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta Optimization",
      "url": "https://arxiv.org/abs/2601.23179"
    },
    {
      "text": "Leveraging LLMs For Turkish Skill Extraction",
      "url": "https://arxiv.org/abs/2601.22885"
    },
    {
      "text": "PSDNorm: Test-Time Temporal Normalization for Deep Learning in Sleep Staging",
      "url": "https://arxiv.org/abs/2503.04582"
    }
  ],
  "centerColumn": [
    {
      "text": "Diffusion Models under Alternative Noise: Simplified Analysis and Sensitivity",
      "url": "https://arxiv.org/abs/2506.08337"
    },
    {
      "text": "Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization",
      "url": "https://arxiv.org/abs/2512.03393"
    },
    {
      "text": "Social World Models",
      "url": "https://arxiv.org/abs/2509.00559"
    },
    {
      "text": "SHAP-Guided Kernel Actor-Critic for Explainable Reinforcement Learning",
      "url": "https://arxiv.org/abs/2512.05291"
    },
    {
      "text": "Automatic Constraint Policy Optimization based on Continuous Constraint Interpolation Framework for Offline Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.23010"
    },
    {
      "text": "RAFFLES: Reasoning-based Attribution of Faults for LLM Systems",
      "url": "https://arxiv.org/abs/2509.06822"
    },
    {
      "text": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective",
      "url": "https://arxiv.org/abs/2505.17652"
    },
    {
      "text": "Collaborative Belief Reasoning with LLMs for Efficient Multi-Agent Collaboration",
      "url": "https://arxiv.org/abs/2509.21981"
    }
  ],
  "rightColumn": [
    {
      "text": "Divide-and-Conquer CoT: RL for Reducing Latency via Parallel Reasoning",
      "url": "https://arxiv.org/abs/2601.23027"
    },
    {
      "text": "From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.23058"
    },
    {
      "text": "Prepare Reasoning Language Models for Multi-Agent Debate with Self-Debate Reinforcement Learning",
      "url": "https://arxiv.org/abs/2601.22297"
    },
    {
      "text": "Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning",
      "url": "https://arxiv.org/abs/2506.05568"
    },
    {
      "text": "Quasiparticle Interference Kernel Extraction with Variational Autoencoders via Latent Alignment",
      "url": "https://arxiv.org/abs/2506.05325"
    },
    {
      "text": "PPO in the Fisher-Rao geometry",
      "url": "https://arxiv.org/abs/2506.03757"
    },
    {
      "text": "How Much Progress Has There Been in NVIDIA Datacenter GPUs?",
      "url": "https://arxiv.org/abs/2601.20115"
    },
    {
      "text": "EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models",
      "url": "https://arxiv.org/abs/2509.11914"
    }
  ],
  "lastUpdated": "2026-02-02T13:14:02Z"
}