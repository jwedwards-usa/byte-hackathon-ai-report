{
  "mainHeadline": {
    "text": "GPT-5.2 IS FRONTIER ONLY FOR THE FRONTIER",
    "url": "https://www.lesswrong.com/posts/Do4eWro8E552isGi5/gpt-5-2-is-frontier-only-for-the-frontier"
  },
  "topStories": [
    {
      "text": "Defending Against Model Weight Exfiltration Through Inference Verification",
      "url": "https://www.lesswrong.com/posts/7i33FDCfcRLJbPs6u/defending-against-model-weight-exfiltration-through-1"
    },
    {
      "text": "What is an evaluation, and how it matters",
      "url": "https://www.lesswrong.com/posts/E9fvqHEDzfLDJTGyq/what-is-an-evaluation-and-how-it-matters"
    },
    {
      "text": "Rotations in Superposition",
      "url": "https://www.alignmentforum.org/posts/LZ7YMPJueB6qjL24n/rotations-in-superposition"
    }
  ],
  "leftColumn": [
    {
      "text": "A Case for Model Persona Research",
      "url": "https://www.lesswrong.com/posts/kCtyhHfpCcWuQkebz/a-case-for-model-persona-research"
    },
    {
      "text": "Generative AI hype distracts us from AI’s more important breakthroughs",
      "url": "https://www.technologyreview.com/2025/12/15/1129179/generative-ai-hype-distracts-us-from-ais-more-important-breakthroughs/"
    },
    {
      "text": "The great AI hype correction of 2025",
      "url": "https://www.technologyreview.com/2025/12/15/1129174/the-great-ai-hype-correction-of-2025/"
    },
    {
      "text": "Stack Overflow users don’t trust AI. They’re using it anyway",
      "url": "https://www.theverge.com/podcast/844073/stack-overflow-ceo-ai-coding-chatgpt-code-red-interview"
    },
    {
      "text": "AI coding is now everywhere. But not everyone is convinced.",
      "url": "https://www.technologyreview.com/2025/12/15/1128352/rise-of-ai-coding-developers-2026/"
    },
    {
      "text": "The AI doomers feel undeterred",
      "url": "https://www.technologyreview.com/2025/12/15/1129171/the-ai-doomers-feel-undeterred/"
    },
    {
      "text": "Nvidia debuts Nemotron 3 with hybrid MoE and Mamba-Transformer to drive efficient agentic AI",
      "url": "https://venturebeat.com/technology/nvidia-debuts-nemotron-3-with-hybrid-moe-and-mamba-transformer-to-drive",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/3xUHPM8pE59D833CnZxxZJ/b8fe73f844b3383d940fda2c5906df94/crimedy7_illustration_of_the_nvidia_colors_in_a_digital_archi_31fa1654-c274-4f35-9673-8879080998cf_1.png?w=300\u0026q=30",
        "alt": "Nvidia debuts Nemotron 3 with hybrid MoE and Mamba-Transformer to drive efficient agentic AI",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "BREAKING THE FROZEN SUBSPACE: IMPORTANCE SAMPLING FOR LOW-RANK OPTIMIZATION IN LLM PRETRAINING",
      "url": "https://arxiv.org/abs/2502.05790"
    }
  ],
  "centerColumn": [
    {
      "text": "ReCode: Unify Plan and Action for Universal Granularity Control",
      "url": "https://arxiv.org/abs/2510.23564"
    },
    {
      "text": "Progress over Points: Reframing LM Benchmarks Around Scientific Objectives",
      "url": "https://arxiv.org/abs/2512.11183"
    },
    {
      "text": "CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise",
      "url": "https://arxiv.org/abs/2512.11282"
    },
    {
      "text": "A Scalable Multi-GPU Framework for Encrypted Large-Model Inference",
      "url": "https://arxiv.org/abs/2512.11269"
    },
    {
      "text": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes",
      "url": "https://arxiv.org/abs/2512.11463"
    },
    {
      "text": "CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction",
      "url": "https://arxiv.org/abs/2511.06634"
    },
    {
      "text": "Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale",
      "url": "https://arxiv.org/abs/2512.10398"
    },
    {
      "text": "Interpretable machine learning of halo gas density profiles: a sensitivity analysis of cosmological hydrodynamical simulations",
      "url": "https://arxiv.org/abs/2512.09021"
    }
  ],
  "rightColumn": [
    {
      "text": "Statistical Analysis of Sentence Structures through ASCII, Lexical Alignment and PCA",
      "url": "https://arxiv.org/abs/2503.10470"
    },
    {
      "text": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning",
      "url": "https://arxiv.org/abs/2512.10534"
    },
    {
      "text": "Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction",
      "url": "https://arxiv.org/abs/2512.11399"
    },
    {
      "text": "Mathematics of natural intelligence",
      "url": "https://arxiv.org/abs/2512.10988"
    },
    {
      "text": "xGR: Efficient Generative Recommendation Serving at Scale",
      "url": "https://arxiv.org/abs/2512.11529"
    },
    {
      "text": "Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning",
      "url": "https://arxiv.org/abs/2512.11485"
    },
    {
      "text": "Visualizing token importance for black-box language models",
      "url": "https://arxiv.org/abs/2512.11573"
    },
    {
      "text": "Elastic-Net Multiple Kernel Learning: Combining Multiple Data Sources for Prediction",
      "url": "https://arxiv.org/abs/2512.11547"
    }
  ],
  "lastUpdated": "2025-12-15T15:31:59Z"
}