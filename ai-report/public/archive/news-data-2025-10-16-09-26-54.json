{
  "mainHeadline": {
    "text": "Anthropic is giving away its powerful Claude Haiku 4.5 AI for free to take on OpenAI",
    "url": "https://venturebeat.com/ai/anthropic-is-giving-away-its-powerful-claude-haiku-4-5-ai-for-free-to-take"
  },
  "topStories": [
    {
      "text": "AI-202X-slowdown: can CoT-based AIs become capable of aligning the ASI?",
      "url": "https://www.lesswrong.com/posts/FGYuXb4cMMmuoggRf/ai-202x-slowdown-can-cot-based-ais-become-capable-of"
    },
    {
      "text": "Introducing Claude Haiku 4.5",
      "url": "https://simonwillison.net/2025/Oct/15/claude-haiku-45/#atom-everything"
    },
    {
      "text": "Position: The Artificial Intelligence and Machine Learning Community Should Adopt a More Transparent and Regulated Peer Review Process",
      "url": "https://arxiv.org/abs/2502.00874"
    }
  ],
  "leftColumn": [
    {
      "text": "Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems",
      "url": "https://arxiv.org/abs/2510.13351"
    },
    {
      "text": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining",
      "url": "https://arxiv.org/abs/2508.21540"
    },
    {
      "text": "Exact Gauss-Newton Optimization for Training Deep Neural Networks",
      "url": "https://arxiv.org/abs/2405.14402"
    },
    {
      "text": "Attention Illuminates LLM Reasoning: The Preplan-and-Anchor Rhythm Enables Fine-Grained Policy Optimization",
      "url": "https://arxiv.org/abs/2510.13554"
    },
    {
      "text": "Taming the Fragility of KV Cache Eviction in LLM Inference",
      "url": "https://arxiv.org/abs/2510.13334"
    },
    {
      "text": "Defending against Stegomalware in Deep Neural Networks with Permutation Symmetry",
      "url": "https://arxiv.org/abs/2509.20399"
    },
    {
      "text": "Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs",
      "url": "https://arxiv.org/abs/2510.03567"
    },
    {
      "text": "Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs",
      "url": "https://arxiv.org/abs/2508.14896"
    }
  ],
  "centerColumn": [
    {
      "text": "Toward LLM-Supported Automated Assessment of Critical Thinking Subskills",
      "url": "https://arxiv.org/abs/2510.12915"
    },
    {
      "text": "DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping",
      "url": "https://arxiv.org/abs/2510.12979"
    },
    {
      "text": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
      "url": "https://arxiv.org/abs/2510.13106"
    },
    {
      "text": "On the Reasoning Abilities of Masked Diffusion Language Models",
      "url": "https://arxiv.org/abs/2510.13117"
    },
    {
      "text": "Evaluating and Mitigating Social Bias for Large Language Models in Open-ended Settings",
      "url": "https://arxiv.org/abs/2412.06134"
    },
    {
      "text": "FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model",
      "url": "https://arxiv.org/abs/2502.01472"
    },
    {
      "text": "MIRROR: Multimodal Cognitive Reframing Therapy for Rolling with Resistance",
      "url": "https://arxiv.org/abs/2504.13211"
    },
    {
      "text": "On the Consistency of Multilingual Context Utilization in Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2504.00597"
    }
  ],
  "rightColumn": [
    {
      "text": "Physics-augmented Multi-task Gaussian Process for Modeling Spatiotemporal Dynamics",
      "url": "https://arxiv.org/abs/2510.13601"
    },
    {
      "text": "UrbanFusion: Stochastic Multimodal Fusion for Contrastive Learning of Robust Spatial Representations",
      "url": "https://arxiv.org/abs/2510.13774"
    },
    {
      "text": "Extreme Compression of Adaptive Neural Images",
      "url": "https://arxiv.org/abs/2405.16807"
    },
    {
      "text": "Manifold Decoders: A Framework for Generative Modeling from Nonlinear Embeddings",
      "url": "https://arxiv.org/abs/2510.13622"
    },
    {
      "text": "Coding without typing the code",
      "url": "https://simonwillison.net/2025/Oct/16/coding-without-typing-the-code/#atom-everything"
    },
    {
      "text": "Writing an LLM from scratch, part 22 – training our LLM",
      "url": "https://www.gilesthomas.com/2025/10/llm-from-scratch-22-finally-training-our-llm"
    },
    {
      "text": "Quoting Catherine Wu",
      "url": "https://simonwillison.net/2025/Oct/15/catherine-wu/#atom-everything"
    },
    {
      "text": "Remembering Professor Emerita Jeanne Shapiro  Bamberger, a pioneer in music education",
      "url": "https://news.mit.edu/2025/remembering-professor-emerita-jeanne-shapiro-bamberger-1015"
    }
  ],
  "lastUpdated": "2025-10-16T09:26:54Z"
}