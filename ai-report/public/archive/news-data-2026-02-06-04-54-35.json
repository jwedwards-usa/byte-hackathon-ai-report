{
  "mainHeadline": {
    "text": "Anthropic's Claude Opus 4.6 brings 1M token context and 'agent teams' to take on OpenAI's Codex",
    "url": "https://venturebeat.com/technology/anthropics-claude-opus-4-6-brings-1m-token-context-and-agent-teams-to-take"
  },
  "topStories": [
    {
      "text": "OpenAI’s GPT-5.3-Codex drops as Anthropic upgrades Claude — AI coding wars heat up ahead of Super Bowl ads",
      "url": "https://venturebeat.com/technology/openais-gpt-5-3-codex-drops-as-anthropic-upgrades-claude-ai-coding-wars-heat"
    },
    {
      "text": "The Simplest Case for AI Catastrophe",
      "url": "https://www.lesswrong.com/posts/uw9etNDaRXGzeuDes/the-simplest-case-for-ai-catastrophe"
    },
    {
      "text": "How Dario Amodei's “The Adolescence of Technology” Delegitimizes AI X-Risk Concerns",
      "url": "https://www.lesswrong.com/posts/3mZ3MnfE7dFWoQCEb/how-dario-amodei-s-the-adolescence-of-technology"
    }
  ],
  "leftColumn": [
    {
      "text": "Beyond the lakehouse: Fundamental's NEXUS bypasses manual ETL with a native foundation model for tabular data",
      "url": "https://venturebeat.com/data/fundamental-emerges-from-stealth-with-first-major-foundation-model-trained",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/xQAJrXCEqJVZZ8XR58deG/1ee37fb8b0f2e5073789a90cd3349caa/3TAB6GEYAOuK63Z49gVbh_7rJTLGX7.png?w=300\u0026q=30",
        "alt": "Beyond the lakehouse: Fundamental's NEXUS bypasses manual ETL with a native foundation model for tabular data",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "Claude Opus 4.6 is Driven",
      "url": "https://www.lesswrong.com/posts/btAn3hydqfgYFyHGW/claude-opus-4-6-is-driven"
    },
    {
      "text": "The nature of LLM algorithmic progress",
      "url": "https://www.lesswrong.com/posts/sGNFtWbXiLJg2hLzK/the-nature-of-llm-algorithmic-progress"
    },
    {
      "text": "INTRODUCING OPENAI FRONTIER",
      "url": "https://openai.com/index/introducing-openai-frontier"
    },
    {
      "text": "AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents",
      "url": "https://arxiv.org/abs/2512.22387"
    },
    {
      "text": "TTT-Discover optimizes GPU kernels 2x faster than human experts — by training during inference",
      "url": "https://venturebeat.com/infrastructure/ttt-discover-optimizes-gpu-kernels-2x-faster-than-human-experts-by-training"
    },
    {
      "text": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem",
      "url": "https://arxiv.org/abs/2602.03969"
    },
    {
      "text": "Sample Blog Post",
      "url": "https://www.anthropic.com/news"
    }
  ],
  "centerColumn": [
    {
      "text": "Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting",
      "url": "https://arxiv.org/abs/2602.04384"
    },
    {
      "text": "Trust The Typical",
      "url": "https://arxiv.org/abs/2602.04581"
    },
    {
      "text": "Rethinking Weight Tying: Pseudo-Inverse Tying for Stable LM Training and Updates",
      "url": "https://arxiv.org/abs/2602.04556"
    },
    {
      "text": "Bayesian PINNs for uncertainty-aware inverse problems (BPINN-IP)",
      "url": "https://arxiv.org/abs/2602.04459"
    },
    {
      "text": "Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning",
      "url": "https://arxiv.org/abs/2602.04340"
    },
    {
      "text": "SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration",
      "url": "https://arxiv.org/abs/2602.04361"
    },
    {
      "text": "Learning to Separate RF Signals Under Uncertainty: Detect-Then-Separate vs. Unified Joint Models",
      "url": "https://arxiv.org/abs/2602.04650"
    },
    {
      "text": "Universal Robust Speech Adaptation for Cross-Domain Speech Recognition and Enhancement",
      "url": "https://arxiv.org/abs/2602.04307"
    }
  ],
  "rightColumn": [
    {
      "text": "Benchmarking Large Language Models for Diagnosing Students' Cognitive Skills from Handwritten Math Work",
      "url": "https://arxiv.org/abs/2504.00843"
    },
    {
      "text": "Billion-Scale Graph Foundation Models",
      "url": "https://arxiv.org/abs/2602.04768"
    },
    {
      "text": "Protein Autoregressive Modeling via Multiscale Structure Generation",
      "url": "https://arxiv.org/abs/2602.04883"
    },
    {
      "text": "Generative Modeling via Drifting",
      "url": "https://arxiv.org/abs/2602.04770"
    },
    {
      "text": "Theory of Optimal Learning Rate Schedules and Scaling Laws for a Random Feature Model",
      "url": "https://arxiv.org/abs/2602.04774"
    },
    {
      "text": "Subliminal Effects in Your Data: A General Mechanism via Log-Linearity",
      "url": "https://arxiv.org/abs/2602.04863"
    },
    {
      "text": "Knowledge Distillation for mmWave Beam Prediction Using Sub-6 GHz Channels",
      "url": "https://arxiv.org/abs/2602.04703"
    },
    {
      "text": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish",
      "url": "https://arxiv.org/abs/2602.04492"
    }
  ],
  "lastUpdated": "2026-02-06T04:54:35Z"
}