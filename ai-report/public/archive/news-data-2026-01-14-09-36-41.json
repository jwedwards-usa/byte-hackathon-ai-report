{
  "mainHeadline": {
    "text": "Brain network science modelling of sparse neural networks enables Transformers and LLMs to perform as fully connected",
    "url": "https://arxiv.org/abs/2501.19107"
  },
  "topStories": [
    {
      "text": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
      "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and"
    },
    {
      "text": "First impressions of Claude Cowork, Anthropic's general agent",
      "url": "https://simonwillison.net/2026/Jan/12/claude-cowork/#atom-everything"
    },
    {
      "text": "A Comparative Study of Traditional Machine Learning, Deep Learning, and Large Language Models for Mental Health Forecasting using Smartphone Sensing Data",
      "url": "https://arxiv.org/abs/2601.03603"
    }
  ],
  "leftColumn": [
    {
      "text": "Global CoT Analysis: Initial attempts to uncover patterns across many chains of thought",
      "url": "https://www.lesswrong.com/posts/q9g9zuudd3Pvw2cbj/global-cot-analysis-initial-attempts-to-uncover-patterns-1"
    },
    {
      "text": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
      "url": "https://arxiv.org/abs/2601.05232"
    },
    {
      "text": "Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock",
      "url": "https://arxiv.org/abs/2601.08673"
    },
    {
      "text": "This new, dead simple prompt technique boosts accuracy on LLMs by up to 76% on non-reasoning tasks",
      "url": "https://venturebeat.com/orchestration/this-new-dead-simple-prompt-technique-boosts-accuracy-on-llms-by-up-to-76-on",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/6PTJl3Wssuvl5m3nljR103/21ab6a44da755c1cf2dca3b8fdd4ad08/cool-guys.png?w=300\u0026q=30",
        "alt": "This new, dead simple prompt technique boosts accuracy on LLMs by up to 76% on non-reasoning tasks",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning",
      "url": "https://arxiv.org/abs/2601.03910"
    },
    {
      "text": "Generalization Analysis and Method for Domain Generalization for a Family of Recurrent Neural Networks",
      "url": "https://arxiv.org/abs/2601.08122"
    },
    {
      "text": "Feed-Forward Optimization With Delayed Feedback for Neural Network Training",
      "url": "https://arxiv.org/abs/2304.13372"
    },
    {
      "text": "How Much of AI Labs' Research Is Safety?",
      "url": "https://www.lesswrong.com/posts/EfCdQeNBaeYtYH374/how-much-of-ai-labs-research-is-safety"
    }
  ],
  "centerColumn": [
    {
      "text": "Out-of-distribution generalization of deep-learning surrogates for 2D PDE-generated dynamics in the small-data regime",
      "url": "https://arxiv.org/abs/2601.08404"
    },
    {
      "text": "Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance",
      "url": "https://arxiv.org/abs/2601.08418"
    },
    {
      "text": "Theoretical Foundations of Prompt Engineering: From Heuristics to Expressivity",
      "url": "https://arxiv.org/abs/2512.12688"
    },
    {
      "text": "High-Fidelity Modeling of Stochastic Chemical Dynamics on Complex Manifolds: A Multi-Scale SIREN-PINN Framework for the Curvature-Perturbed Ginzburg-Landau Equation",
      "url": "https://arxiv.org/abs/2601.08104"
    },
    {
      "text": "Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs",
      "url": "https://arxiv.org/abs/2601.08403"
    },
    {
      "text": "Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models",
      "url": "https://arxiv.org/abs/2601.08383"
    },
    {
      "text": "PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images",
      "url": "https://arxiv.org/abs/2601.08127"
    },
    {
      "text": "Qalb: Largest State-of-the-Art Urdu Large Language Model for 230M Speakers with Systematic Continued Pre-training",
      "url": "https://arxiv.org/abs/2601.08141"
    }
  ],
  "rightColumn": [
    {
      "text": "Sliced-Wasserstein Distribution Alignment Loss Improves the Ultra-Low-Bit Quantization of Large Language Models",
      "url": "https://arxiv.org/abs/2601.07878"
    },
    {
      "text": "A Preliminary Agentic Framework for Matrix Deflation",
      "url": "https://arxiv.org/abs/2601.08219"
    },
    {
      "text": "Tackling Heterogeneity in Quantum Federated Learning: An Integrated Sporadic-Personalized Approach",
      "url": "https://arxiv.org/abs/2601.07882"
    },
    {
      "text": "Affect and Effect: Limitations of regularisation-based continual learning in EEG-based emotion classification",
      "url": "https://arxiv.org/abs/2601.07858"
    },
    {
      "text": "Immunological Density Shapes Recovery Trajectories in Long COVID",
      "url": "https://arxiv.org/abs/2601.07854"
    },
    {
      "text": "TabPFN Through The Looking Glass: An interpretability study of TabPFN and its internal representations",
      "url": "https://arxiv.org/abs/2601.08181"
    },
    {
      "text": "Incorporating Cognitive Biases into Reinforcement Learning for Financial Decision-Making",
      "url": "https://arxiv.org/abs/2601.08247"
    },
    {
      "text": "Large-scale Regional Traffic Signal Control Based on Single-Agent Reinforcement Learning",
      "url": "https://arxiv.org/abs/2503.09252"
    }
  ],
  "lastUpdated": "2026-01-14T09:36:41Z"
}