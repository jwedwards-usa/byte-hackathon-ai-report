{
  "mainHeadline": {
    "text": "Towards New Benchmark for AI Alignment \u0026 Sentiment Analysis in Socially Important Issues: A Comparative Study of Human and LLMs in the Context of AGI",
    "url": "https://arxiv.org/abs/2501.02531"
  },
  "topStories": [
    {
      "text": "UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat",
      "url": "https://arxiv.org/abs/2508.17378"
    },
    {
      "text": "LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts",
      "url": "https://arxiv.org/abs/2508.16325"
    },
    {
      "text": "Hidden Reasoning in LLMs: A Taxonomy",
      "url": "https://www.lesswrong.com/posts/ZrgFfeWuckpwK5Lyi/hidden-reasoning-in-llms-a-taxonomy"
    }
  ],
  "leftColumn": [
    {
      "text": "The Download: Americaâ€™s drone brothers, and an upside of AI doomerism",
      "url": "https://www.technologyreview.com/2025/08/26/1122511/the-download-americas-drone-brothers-and-an-upside-of-ai-doomerism/"
    },
    {
      "text": "BREAKING THE EXPLORATION BOTTLENECK: RUBRIC-SCAFFOLDED REINFORCEMENT LEARNING FOR GENERAL LLM REASONING",
      "url": "https://arxiv.org/abs/2508.16949"
    },
    {
      "text": "Decoding Alignment: A Critical Survey of LLM Development Initiatives through Value-setting and Data-centric Lens",
      "url": "https://arxiv.org/abs/2508.16982"
    },
    {
      "text": "FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline",
      "url": "https://arxiv.org/abs/2508.16514"
    },
    {
      "text": "Let's Use ChatGPT To Write Our Paper! Benchmarking LLMs To Write the Introduction of a Research Paper",
      "url": "https://arxiv.org/abs/2508.14273"
    },
    {
      "text": "Proactive AI Control: A Case for Battery-Dependent Systems",
      "url": "https://www.lesswrong.com/posts/vudjtmNwGDKMCPeev/proactive-ai-control-a-case-for-battery-dependent-systems"
    },
    {
      "text": "WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling",
      "url": "https://arxiv.org/abs/2508.16676"
    },
    {
      "text": "A Laplace diffusion-based transformer model for heart rate forecasting within daily activity context",
      "url": "https://arxiv.org/abs/2508.16655"
    }
  ],
  "centerColumn": [
    {
      "text": "DRQA: Dynamic Reasoning Quota Allocation for Controlling Overthinking in Reasoning Large Language Models",
      "url": "https://arxiv.org/abs/2508.17803"
    },
    {
      "text": "Speech Discrete Tokens or Continuous Features? A Comparative Analysis for Spoken Language Understanding in SpeechLLMs",
      "url": "https://arxiv.org/abs/2508.17863"
    },
    {
      "text": "MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains",
      "url": "https://arxiv.org/abs/2508.18260"
    },
    {
      "text": "From BERT to LLMs: Comparing and Understanding Chinese Classifier Prediction in Language Models",
      "url": "https://arxiv.org/abs/2508.18253"
    },
    {
      "text": "Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios",
      "url": "https://arxiv.org/abs/2508.18183"
    },
    {
      "text": "DiscussLLM: Teaching Large Language Models When to Speak",
      "url": "https://arxiv.org/abs/2508.18167"
    },
    {
      "text": "Neither Valid nor Reliable? Investigating the Use of LLMs as Judges",
      "url": "https://arxiv.org/abs/2508.18076"
    },
    {
      "text": "THE CTO WAS CHATGPT",
      "url": "https://ehandbook.com/the-cto-was-chatgpt-63606f7056ef"
    }
  ],
  "rightColumn": [
    {
      "text": "Enhanced NIRMAL Optimizer With Damped Nesterov Acceleration: A Comparative Analysis",
      "url": "https://arxiv.org/abs/2508.16550"
    },
    {
      "text": "Revisiting Differentially Private Hyper-parameter Tuning",
      "url": "https://arxiv.org/abs/2402.13087"
    },
    {
      "text": "Towards Open World Detection: A Survey",
      "url": "https://arxiv.org/abs/2508.16527"
    },
    {
      "text": "Does simple trump complex? Comparing strategies for adversarial robustness in DNNs",
      "url": "https://arxiv.org/abs/2508.18019"
    },
    {
      "text": "Weights-Rotated Preference Optimization for Large Language Models",
      "url": "https://arxiv.org/abs/2508.17637"
    },
    {
      "text": "RephraseTTS: Dynamic Length Text based Speech Insertion with Speaker Style Transfer",
      "url": "https://arxiv.org/abs/2508.17031"
    },
    {
      "text": "Flash Sparse Attention: An Alternative Efficient Implementation of Native Sparse Attention Kernel",
      "url": "https://arxiv.org/abs/2508.18224"
    },
    {
      "text": "CoCoA: Confidence- and Context-Aware Adaptive Decoding for Resolving Knowledge Conflicts in Large Language Models",
      "url": "https://arxiv.org/abs/2508.17670"
    }
  ],
  "lastUpdated": "2025-08-26T12:50:36Z"
}