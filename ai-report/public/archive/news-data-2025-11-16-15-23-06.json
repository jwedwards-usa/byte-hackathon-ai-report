{
  "mainHeadline": {
    "text": "Considering the Relevance of Computational Uncertainty for AI Safety",
    "url": "https://www.lesswrong.com/posts/EFMpYDqCWikpbvQ9X/considering-the-relevance-of-computational-uncertainty-for"
  },
  "topStories": [
    {
      "text": "CHATGPT GROUP CHATS ARE HERE … BUT NOT FOR EVERYONE (YET)",
      "url": "https://venturebeat.com/ai/chatgpt-group-chats-are-here-but-not-for-everyone-yet",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/4lD8xHoLueH39q7LYaoY0X/d121a8f4d69e53cb4ed2e6894726b7fb/gYge-sBdNYW1QP2kJADr-.png?w=300\u0026q=30",
        "alt": "ChatGPT Group Chats are here … but not for everyone (yet)",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "Will AI systems drift into misalignment?",
      "url": "https://www.alignmentforum.org/posts/u8TYRhGPD878i3qkc/will-ai-systems-drift-into-misalignment"
    },
    {
      "text": "llm-anthropic 0.22",
      "url": "https://simonwillison.net/2025/Nov/15/llm-anthropic-022/#atom-everything"
    }
  ],
  "leftColumn": [
    {
      "text": "Sample Blog Post",
      "url": "https://www.anthropic.com/news"
    },
    {
      "text": "Stop Worrying about AGI: The Immediate Danger is Reduced General Intelligence (RGI)",
      "url": "https://towardsdatascience.com/stop-worrying-about-agi-the-immediate-danger-is-reduced-general-intelligence-rgi/"
    },
    {
      "text": "I Measured Neural Network Training Every 5 Steps for 10,000 Iterations",
      "url": "https://towardsdatascience.com/i-measured-neural-network-training-every-5-steps-for-10000-iterations/"
    },
    {
      "text": "Google’s new AI training method helps small models tackle complex reasoning",
      "url": "https://venturebeat.com/ai/googles-new-ai-training-method-helps-small-models-tackle-complex-reasoning"
    },
    {
      "text": "Support the Movement against AI extinction risk",
      "url": "https://www.lesswrong.com/posts/CjkQvuQpFffxYcJsR/support-the-movement-against-ai-extinction-risk"
    },
    {
      "text": "Now, “Tethering” is a Bigger Educational Problem Than “Involution”",
      "url": "https://www.lesswrong.com/posts/HirN5p64y3BRq8mij/now-tethering-is-a-bigger-educational-problem-than"
    }
  ],
  "centerColumn": [
    {
      "text": "Put numbers on stuff, all the time, otherwise scope insensitivity will eat you",
      "url": "https://www.lesswrong.com/posts/sdvBcPSR7p5mKhB7b/put-numbers-on-stuff-all-the-time-otherwise-scope"
    },
    {
      "text": "How to Automate Workflows with AI",
      "url": "https://towardsdatascience.com/how-to-automate-workflows-with-ai/"
    },
    {
      "text": "Databricks: 'PDF parsing for agentic AI is still unsolved' — new tool replaces multi-service pipelines with single function",
      "url": "https://venturebeat.com/data-infrastructure/databricks-pdf-parsing-for-agentic-ai-is-still-unsolved-new-tool-replaces"
    },
    {
      "text": "Brand New Experience Salesman",
      "url": "https://www.lesswrong.com/posts/NPWKAFsDYtfY4zw5Z/brand-new-experience-salesman"
    },
    {
      "text": "7 Vicious Vices of Rationalists",
      "url": "https://www.lesswrong.com/posts/r6xSmbJRK9KKLcXTM/7-vicious-vices-of-rationalists-1"
    },
    {
      "text": "Blocking LLM crawlers without JavaScript",
      "url": "https://www.owl.is/blogg/blocking-crawlers-without-javascript/"
    }
  ],
  "rightColumn": [
    {
      "text": "“The success of an AI product depends on how intuitively users can interact with its capabilities”",
      "url": "https://towardsdatascience.com/the-success-of-an-ai-product-depends-on-how-intuitively-users-can-interact-with-its-capabilities/"
    },
    {
      "text": "How to Crack Machine Learning System-Design Interviews",
      "url": "https://towardsdatascience.com/cracking-machine-learning-system-design-interviews/"
    },
    {
      "text": "THE BADNESS OF DEATH IN DIFFERENT METAETHICAL THEORIES",
      "url": "https://www.lesswrong.com/posts/iBg6AAG72wqyosxAk/the-badness-of-death-in-different-metaethical-theories"
    },
    {
      "text": "Diagonalization: A (slightly) more rigorous model of paranoia",
      "url": "https://www.lesswrong.com/posts/rmkbneSMQHZJ5Svbk/diagonalization-a-slightly-more-rigorous-model-of-paranoia"
    },
    {
      "text": "Finding My Internal Compass, Literally",
      "url": "https://www.lesswrong.com/posts/frWzWznQ68c6isB2m/finding-my-internal-compass-literally"
    },
    {
      "text": "The Ambiguity Of \"Human Values\" Is A Feature, Not A Bug",
      "url": "https://www.lesswrong.com/posts/W3pKCNPck63vD2Wez/the-ambiguity-of-human-values-is-a-feature-not-a-bug"
    },
    {
      "text": "parakeet-mlx",
      "url": "https://simonwillison.net/2025/Nov/14/parakeet-mlx/#atom-everything"
    }
  ],
  "lastUpdated": "2025-11-16T15:23:06Z"
}