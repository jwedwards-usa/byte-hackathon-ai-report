{
  "mainHeadline": {
    "text": "Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans",
    "url": "https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding"
  },
  "topStories": [
    {
      "text": "What enterprises should know about The White House's new AI 'Manhattan Project' the Genesis Mission",
      "url": "https://venturebeat.com/ai/what-enterprises-should-know-about-the-white-houses-new-ai-manhattan-project",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/5m2x1YdAEaqWJLhiH1Oh3S/cf8162a0477a1a70dbebd393e0ce2a3d/0hw9lFQJS_Zy6yiTAktWc.png?w=300\u0026q=30",
        "alt": "What enterprises should know about The White House's new AI 'Manhattan Project' the Genesis Mission",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "CHATGPT 5.1 CODEX MAX",
      "url": "https://www.lesswrong.com/posts/YMFYQpsY2MGbXKPtS/chatgpt-5-1-codex-max"
    },
    {
      "text": "Claude Opus 4.5, and why evaluating new LLMs is increasingly difficult",
      "url": "https://simonwillison.net/2025/Nov/24/claude-opus/#atom-everything"
    }
  ],
  "leftColumn": [
    {
      "text": "Expanding data residency access to business customers worldwide",
      "url": "https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide"
    },
    {
      "text": "Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces",
      "url": "https://arxiv.org/abs/2511.19333"
    },
    {
      "text": "ChatGPT shopping research builds you a buyer’s guide using AI",
      "url": "https://www.theverge.com/news/828326/chatgpt-shopping-research-chatgpt-buyers-guide"
    },
    {
      "text": "Anthropic’s new model is its latest frontier in the AI agent battle — but it’s still facing cybersecurity concerns",
      "url": "https://www.theverge.com/ai-artificial-intelligence/828003/anthropics-new-claude-opus-4-5-model-ai-agents-cybersecurity"
    },
    {
      "text": "Microsoft’s Fara-7B is a computer-use AI agent that rivals GPT-4o and works directly on your PC",
      "url": "https://venturebeat.com/ai/microsofts-fara-7b-is-a-computer-use-ai-agent-that-rivals-gpt-4o-and-works"
    },
    {
      "text": "Security Complacency Meets Frontier AI: The Coming Collapse of ‘Secure by Apathy’",
      "url": "https://www.lesswrong.com/posts/6peXANM4HhQv6rHyo/security-complacency-meets-frontier-ai-the-coming-collapse"
    },
    {
      "text": "llm-anthropic 0.23",
      "url": "https://simonwillison.net/2025/Nov/25/llm-anthropic/#atom-everything"
    },
    {
      "text": "The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility",
      "url": "https://arxiv.org/abs/2511.18302"
    }
  ],
  "centerColumn": [
    {
      "text": "General-Purpose Models for the Chemical Sciences: LLMs and Beyond",
      "url": "https://arxiv.org/abs/2507.07456"
    },
    {
      "text": "LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems",
      "url": "https://arxiv.org/abs/2511.19368"
    },
    {
      "text": "3D Dynamic Radio Map Prediction Using Vision Transformers for Low-Altitude Wireless Networks",
      "url": "https://arxiv.org/abs/2511.19019"
    },
    {
      "text": "Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect",
      "url": "https://arxiv.org/abs/2511.18854"
    },
    {
      "text": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
      "url": "https://arxiv.org/abs/2511.18849"
    },
    {
      "text": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
      "url": "https://arxiv.org/abs/2511.18842"
    },
    {
      "text": "Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives",
      "url": "https://arxiv.org/abs/2511.18507"
    },
    {
      "text": "Fine-Grained GRPO for Precise Preference Alignment in Flow Models",
      "url": "https://arxiv.org/abs/2510.01982"
    }
  ],
  "rightColumn": [
    {
      "text": "DocPTBench: Benchmarking End-to-End Photographed Document Parsing and Translation",
      "url": "https://arxiv.org/abs/2511.18434"
    },
    {
      "text": "DiM-TS: Bridge the Gap between Selective State Space Models and Time Series for Generative Modeling",
      "url": "https://arxiv.org/abs/2511.18312"
    },
    {
      "text": "FastMMoE: Accelerating Multimodal Large Language Models through Dynamic Expert Activation and Routing-Aware Token Pruning",
      "url": "https://arxiv.org/abs/2511.17885"
    },
    {
      "text": "DynamiX: Dynamic Resource eXploration for Personalized Ad-Recommendations",
      "url": "https://arxiv.org/abs/2511.18331"
    },
    {
      "text": "OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph",
      "url": "https://arxiv.org/abs/2511.18622"
    },
    {
      "text": "Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary Gene Selection",
      "url": "https://arxiv.org/abs/2511.18336"
    },
    {
      "text": "A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News",
      "url": "https://arxiv.org/abs/2511.18618"
    },
    {
      "text": "A Benchmark for Zero-Shot Belief Inference in Large Language Models",
      "url": "https://arxiv.org/abs/2511.18616"
    }
  ],
  "lastUpdated": "2025-11-25T18:38:42Z"
}