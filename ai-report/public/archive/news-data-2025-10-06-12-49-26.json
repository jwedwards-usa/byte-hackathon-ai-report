{
  "mainHeadline": {
    "text": "LLMs one-box when in a \"hostile telepath\" version of Newcomb's Paradox, except for the one that beat the predictor",
    "url": "https://www.lesswrong.com/posts/gsRMdE56oqrZrXX6D/llms-one-box-when-in-a-hostile-telepath-version-of-newcomb-s"
  },
  "topStories": [
    {
      "text": "XBREAKING: EXPLAINABLE ARTIFICIAL INTELLIGENCE FOR JAILBREAKING LLMS",
      "url": "https://arxiv.org/abs/2504.21700"
    },
    {
      "text": "BrainIB++: Leveraging Graph Neural Networks and Information Bottleneck for Functional Brain Biomarkers in Schizophrenia",
      "url": "https://arxiv.org/abs/2510.03004"
    },
    {
      "text": "Fictional characters are (officially) coming to Sora as OpenAI manages copyright chaos",
      "url": "https://www.theverge.com/news/792661/sora-fictional-copyright-characters"
    }
  ],
  "leftColumn": [
    {
      "text": "AMD teams up with OpenAI to challenge Nvidiaâ€™s AI chip dominance",
      "url": "https://www.theverge.com/news/792650/amd-openai-five-year-ai-chip-agreement"
    },
    {
      "text": "AI Science Companies: Evidence AGI Is Near\n",
      "url": "https://www.lesswrong.com/posts/Dmkmc3kPcdcHhontA/ai-science-companies-evidence-agi-is-near"
    },
    {
      "text": "Base64Bench: How good are LLMs at base64, and why care about it?",
      "url": "https://www.lesswrong.com/posts/5F6ncBfjh2Bxnm6CJ/base64bench-how-good-are-llms-at-base64-and-why-care-about"
    },
    {
      "text": "2025 Climate Tech Companies to Watch: Pairwise and its climate-adapted crops",
      "url": "https://www.technologyreview.com/2025/10/06/1124278/2025-climate-tech-companies-to-watch-pairwise-gene-edited-crops/"
    },
    {
      "text": "AMD and OpenAI announce strategic partnership to deploy 6 gigawatts of AMD GPUs",
      "url": "https://openai.com/index/openai-amd-strategic-partnership"
    },
    {
      "text": "Behavior Best-of-N achieves Near Human Performance on Computer Tasks",
      "url": "https://www.lesswrong.com/posts/rft2jio6CzvmsvTua/behavior-best-of-n-achieves-near-human-performance-on"
    },
    {
      "text": "Sample Blog Post",
      "url": "https://www.anthropic.com/news"
    },
    {
      "text": "The Download: introducing the 10 climate tech companies to watch for 2025",
      "url": "https://www.technologyreview.com/2025/10/06/1124939/the-download-introducing-the-10-climate-tech-companies-to-watch-for-2025/"
    }
  ],
  "centerColumn": [
    {
      "text": "Untargeted Jailbreak Attack",
      "url": "https://arxiv.org/abs/2510.02999"
    },
    {
      "text": "ToolTweak: An Attack on Tool Selection in LLM-based Agents",
      "url": "https://arxiv.org/abs/2510.02554"
    },
    {
      "text": "AI Generated Child Sexual Abuse Material - What's the Harm?",
      "url": "https://arxiv.org/abs/2510.02978"
    },
    {
      "text": "How Confident are Video Models? Empowering Video Models to Express their Uncertainty",
      "url": "https://arxiv.org/abs/2510.02571"
    },
    {
      "text": "Semantic Similarity in Radiology Reports via LLMs and NER",
      "url": "https://arxiv.org/abs/2510.03102"
    },
    {
      "text": "In-memory Training on Analog Devices with Limited Conductance States via Multi-tile Residual Learning",
      "url": "https://arxiv.org/abs/2510.02516"
    },
    {
      "text": "Listening or Reading? Evaluating Speech Awareness in Chain-of-Thought Speech-to-Text Translation",
      "url": "https://arxiv.org/abs/2510.03115"
    },
    {
      "text": "When Researchers Say Mental Model/Theory of Mind of AI, What Are They Really Talking About?",
      "url": "https://arxiv.org/abs/2510.02660"
    }
  ],
  "rightColumn": [
    {
      "text": "The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models",
      "url": "https://arxiv.org/abs/2507.16076"
    },
    {
      "text": "RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering",
      "url": "https://arxiv.org/abs/2509.16360"
    },
    {
      "text": "Learning to Parallel: Accelerating Diffusion Large Language Models via Learnable Parallel Decoding",
      "url": "https://arxiv.org/abs/2509.25188"
    },
    {
      "text": "Improving Online-to-Nonconvex Conversion for Smooth Optimization via Double Optimism",
      "url": "https://arxiv.org/abs/2510.03167"
    },
    {
      "text": "Cross-Platform DNA Methylation Classifier for the Eight Molecular Subtypes of Group 3 \u0026 4 Medulloblastoma",
      "url": "https://arxiv.org/abs/2510.02416"
    },
    {
      "text": "Enhancing Large Language Model Reasoning with Reward Models: An Analytical Survey",
      "url": "https://arxiv.org/abs/2510.01925"
    },
    {
      "text": "ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment",
      "url": "https://arxiv.org/abs/2510.02876"
    },
    {
      "text": "Bootstrap Learning for Combinatorial Graph Alignment with Sequential GNNs",
      "url": "https://arxiv.org/abs/2510.03086"
    }
  ],
  "lastUpdated": "2025-10-06T12:49:26Z"
}