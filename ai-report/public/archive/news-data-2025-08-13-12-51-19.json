{
  "mainHeadline": {
    "text": "Anthropic details its AI safety strategy",
    "url": "https://www.artificialintelligence-news.com/news/anthropic-details-ai-safety-strategy/"
  },
  "topStories": [
    {
      "text": "Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code",
      "url": "https://arxiv.org/abs/2508.08322"
    },
    {
      "text": "Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams",
      "url": "https://arxiv.org/abs/2508.09036"
    },
    {
      "text": "OpenAI brings GPT-4o back as a default for all paying ChatGPT users, Altman promises ‘plenty of notice’ if it leaves again",
      "url": "https://venturebeat.com/ai/openai-brings-gpt-4o-back-as-a-default-for-all-paying-chatgpt-users-altman-promises-plenty-of-notice-if-it-leaves-again/"
    }
  ],
  "leftColumn": [
    {
      "text": "OpenAI adds new ChatGPT third-party tool connectors to Dropbox, MS Teams as Altman clarifies GPT-5 prioritization",
      "url": "https://venturebeat.com/ai/openai-adds-new-chatgpt-third-party-tool-connectors-to-dropbox-ms-teams-as-altman-clarifies-gpt-5-prioritization/"
    },
    {
      "text": "ChatGPT won’t remove old models without warning after GPT-5 backlash",
      "url": "https://www.theverge.com/openai/758537/chatgpt-4o-gpt-5-model-backlash-replacement"
    },
    {
      "text": "Paper Review: TRImodal Brain Encoder\nfor whole-brain fMRI response prediction (TRIBE)",
      "url": "https://www.lesswrong.com/posts/JY9fXGzsAv8Pdgmje/paper-review-trimodal-brain-encoder-for-whole-brain-fmri"
    },
    {
      "text": "The Download: Trump’s golden dome, and fueling AI with nuclear power",
      "url": "https://www.technologyreview.com/2025/08/13/1121722/the-download-trumps-golden-dome-and-fueling-ai-with-nuclear-power/"
    },
    {
      "text": "Fast weight programming and linear transformers: from machine learning to neurobiology",
      "url": "https://arxiv.org/abs/2508.08435"
    },
    {
      "text": "OpenAI is editing its GPT-5 rollout on the fly — here’s what’s changing in ChatGPT",
      "url": "https://venturebeat.com/ai/openai-is-editing-its-gpt-5-rollout-on-the-fly-heres-whats-changing-in-chatgpt/"
    },
    {
      "text": "Why Trump’s “golden dome” missile defense idea is another ripped straight from the movies",
      "url": "https://www.technologyreview.com/2025/08/13/1121332/trump-golden-dome-missile-defense-national-security/"
    },
    {
      "text": "Energy-Aware Code Generation with LLMs: Benchmarking Small vs. Large Language Models for Sustainable AI Programming",
      "url": "https://arxiv.org/abs/2508.08332"
    }
  ],
  "centerColumn": [
    {
      "text": "Deep Neural Network Calibration by Reducing Classifier Shift with Stochastic Masking",
      "url": "https://arxiv.org/abs/2508.09116"
    },
    {
      "text": "SafeFix: Targeted Model Repair via Controlled Image Generation",
      "url": "https://arxiv.org/abs/2508.08701"
    },
    {
      "text": "Do AI Companies Make Good on Voluntary Commitments to the White House?",
      "url": "https://arxiv.org/abs/2508.08345"
    },
    {
      "text": "Neural Artistic Style and Color Transfer Using Deep Learning",
      "url": "https://arxiv.org/abs/2508.08608"
    },
    {
      "text": "Sam Altman now says AGI, or human-level AI, is 'not a super useful term'",
      "url": "https://www.cnbc.com/2025/08/11/sam-altman-says-agi-is-a-pointless-term-experts-agree.html"
    },
    {
      "text": "The end of perimeter defense: When your own AI tools become the threat actor",
      "url": "https://venturebeat.com/security/black-hat-2025-chatgpt-copilot-deepseek-now-create-malware/"
    },
    {
      "text": "Coconut: A Framework for Latent Reasoning in LLMs",
      "url": "https://towardsdatascience.com/coconut-a-framework-for-latent-reasoning-in-llms/"
    },
    {
      "text": "Quoting Nick Turley",
      "url": "https://simonwillison.net/2025/Aug/12/nick-turley/#atom-everything"
    }
  ],
  "rightColumn": [
    {
      "text": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
      "url": "https://arxiv.org/abs/2508.08875"
    },
    {
      "text": "Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models",
      "url": "https://arxiv.org/abs/2508.08879"
    },
    {
      "text": "Towards Universal Neural Inference",
      "url": "https://arxiv.org/abs/2508.09100"
    },
    {
      "text": "BiasGym: Fantastic Biases and How to Find (and Remove) Them",
      "url": "https://arxiv.org/abs/2508.08855"
    },
    {
      "text": "Hi-fi functional priors by learning activations",
      "url": "https://arxiv.org/abs/2508.08880"
    },
    {
      "text": "Subsampling Factorization Machine Annealing",
      "url": "https://arxiv.org/abs/2508.08778"
    },
    {
      "text": "Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery",
      "url": "https://arxiv.org/abs/2508.08401"
    },
    {
      "text": "Stationarity Exploration for Multivariate Time Series Forecasting",
      "url": "https://arxiv.org/abs/2508.08919"
    }
  ],
  "lastUpdated": "2025-08-13T12:51:19Z"
}