{
  "mainHeadline": {
    "text": "Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT",
    "url": "https://openai.com/index/retiring-gpt-4o-and-older-models"
  },
  "topStories": [
    {
      "text": "An explainable vision transformer with transfer learning based efficient drought stress identification",
      "url": "https://arxiv.org/abs/2407.21666"
    },
    {
      "text": "Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond",
      "url": "https://arxiv.org/abs/2601.21767"
    },
    {
      "text": "Fairy2i: Training Complex LLMs from Real LLMs with All Parameters in $\\{\\pm 1, \\pm i\\}$",
      "url": "https://arxiv.org/abs/2512.02901"
    }
  ],
  "leftColumn": [
    {
      "text": "Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text",
      "url": "https://arxiv.org/abs/2601.21895"
    },
    {
      "text": "A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition",
      "url": "https://arxiv.org/abs/2601.21802"
    },
    {
      "text": "DBELLQUANT: BREAKING THE BELL WITH DOUBLE-BELL TRANSFORMATION FOR LLMS POST TRAINING BINARIZATION",
      "url": "https://arxiv.org/abs/2507.01027"
    },
    {
      "text": "Bridging On-Device and Cloud LLMs for Collaborative Reasoning: A Unified Methodology for Local Routing and Post-Training",
      "url": "https://arxiv.org/abs/2509.24050"
    },
    {
      "text": "Are We in a Continual Learning Overhang?",
      "url": "https://www.lesswrong.com/posts/Lby4gMvKcLPoozHfg/are-we-in-a-continual-learning-overhang-1"
    },
    {
      "text": "Taisei Corporation shapes the next generation of talent with ChatGPT",
      "url": "https://openai.com/index/taisei"
    },
    {
      "text": "\"Not in My Backyard\": LLMs Uncover Online and Offline Social Biases Against Homelessness",
      "url": "https://arxiv.org/abs/2508.13187"
    },
    {
      "text": "Ostrakon-VL: Towards Domain-Expert MLLM for Food-Service and Retail Stores",
      "url": "https://arxiv.org/abs/2601.21342"
    }
  ],
  "centerColumn": [
    {
      "text": "Theoretically Optimal Attention/FFN Ratios in Disaggregated LLM Serving",
      "url": "https://arxiv.org/abs/2601.21351"
    },
    {
      "text": "Conditional Generative Framework with Peak-Aware Attention for Robust Chemical Detection under Interferences",
      "url": "https://arxiv.org/abs/2601.21246"
    },
    {
      "text": "Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models",
      "url": "https://arxiv.org/abs/2512.00590"
    },
    {
      "text": "Heterogeneous Vertiport Selection Optimization for On-Demand Air Taxi Services: A Deep Reinforcement Learning Approach",
      "url": "https://arxiv.org/abs/2601.21316"
    },
    {
      "text": "Distributionally Robust Classification for Multi-source Unsupervised Domain Adaptation",
      "url": "https://arxiv.org/abs/2601.21315"
    },
    {
      "text": "EnsembleLink: Accurate Record Linkage Without Training Data",
      "url": "https://arxiv.org/abs/2601.21138"
    },
    {
      "text": "Heterogeneous Computing: The Key to Powering the Future of AI Agent Inference",
      "url": "https://arxiv.org/abs/2601.22001"
    },
    {
      "text": "LoRIF: Low-Rank Influence Functions for Scalable Training Data Attribution",
      "url": "https://arxiv.org/abs/2601.21929"
    }
  ],
  "rightColumn": [
    {
      "text": "CORDS: Continuous Representations of Discrete Structures",
      "url": "https://arxiv.org/abs/2601.21583"
    },
    {
      "text": "When does predictive inverse dynamics outperform behavior cloning?",
      "url": "https://arxiv.org/abs/2601.21718"
    },
    {
      "text": "MK-SGC-SC: Multiple Kernel Guided Sparse Graph Construction in Spectral Clustering for Unsupervised Speaker Diarization",
      "url": "https://arxiv.org/abs/2601.19946"
    },
    {
      "text": "Amortized Spectral Kernel Discovery via Prior-Data Fitted Network",
      "url": "https://arxiv.org/abs/2601.21731"
    },
    {
      "text": "Shaping capabilities with token-level data filtering",
      "url": "https://arxiv.org/abs/2601.21571"
    },
    {
      "text": "Why Adam Works Better with $\\beta_1 = \\beta_2$: The Missing Gradient Scale Invariance Principle",
      "url": "https://arxiv.org/abs/2601.21739"
    },
    {
      "text": "Bridging Functional and Representational Similarity via Usable Information",
      "url": "https://arxiv.org/abs/2601.21568"
    },
    {
      "text": "FlexCausal: Flexible Causal Disentanglement via Structural Flow Priors and Manifold-Aware Interventions",
      "url": "https://arxiv.org/abs/2601.21567"
    }
  ],
  "lastUpdated": "2026-01-30T09:47:32Z"
}