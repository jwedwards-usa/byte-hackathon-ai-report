{
  "mainHeadline": {
    "text": "First impressions of Claude Cowork, Anthropic's general agent",
    "url": "https://simonwillison.net/2026/Jan/12/claude-cowork/#atom-everything"
  },
  "topStories": [
    {
      "text": "Making LLM Graders Consistent",
      "url": "https://www.lesswrong.com/posts/ANHWxoKSM7baDEqob/making-llm-graders-consistent"
    },
    {
      "text": "BlackBoxQuery [BBQ]-Bench: Measuring Hypothesis Formation and Experimentation Capabilities in LLMs",
      "url": "https://www.lesswrong.com/posts/fFuwW2nE5rZNSFQmY/blackboxquery-bbq-bench-measuring-hypothesis-formation-and-1"
    },
    {
      "text": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
      "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no"
    }
  ],
  "leftColumn": [
    {
      "text": "Automating Deception: Scalable Multi-Turn LLM Jailbreaks",
      "url": "https://arxiv.org/abs/2511.19517"
    },
    {
      "text": "Anthropic wants you to use Claude to ‘Cowork’ in latest AI agent push",
      "url": "https://www.theverge.com/ai-artificial-intelligence/860730/anthropic-cowork-feature-ai-agents-claude-code"
    },
    {
      "text": "Attempting to influence transformer representations via initialization",
      "url": "https://www.lesswrong.com/posts/4nTDGhCT7nxrtLXdf/attempting-to-influence-transformer-representations-via"
    },
    {
      "text": "Tensor-Transformer Variants are Surprisingly Performant",
      "url": "https://www.lesswrong.com/posts/hp9bvkiN3RzHgP9cq/tensor-transformer-variants-are-surprisingly-performant"
    },
    {
      "text": "Brief Explorations in LLM Value Rankings",
      "url": "https://www.alignmentforum.org/posts/k6HKzwqCY4wKncRkM/brief-explorations-in-llm-value-rankings"
    },
    {
      "text": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset",
      "url": "https://arxiv.org/abs/2601.05918"
    },
    {
      "text": "KNOWLEDGE-DRIVEN MULTI-TURN JAILBREAKING ON LARGE LANGUAGE MODELS",
      "url": "https://arxiv.org/abs/2601.05445"
    },
    {
      "text": "MULTI-TURN JAILBREAKING ATTACK IN MULTI-MODAL LARGE LANGUAGE MODELS",
      "url": "https://arxiv.org/abs/2601.05339"
    }
  ],
  "centerColumn": [
    {
      "text": "Text Detoxification in isiXhosa and Yor\\`ub\\'a: A Cross-Lingual Machine Learning Approach for Low-Resource African Languages",
      "url": "https://arxiv.org/abs/2601.05624"
    },
    {
      "text": "Dating Roundup #10: Gendered Expectations",
      "url": "https://www.lesswrong.com/posts/zphaHyABxMEDqNQ7K/dating-roundup-10-gendered-expectations"
    },
    {
      "text": "How AI Can Become Your Personal Language Tutor",
      "url": "https://towardsdatascience.com/how-ai-can-become-your-personal-language-tutor/"
    },
    {
      "text": "Securing digital assets as crypto crime surges",
      "url": "https://www.technologyreview.com/2026/01/12/1129479/securing-digital-assets-as-crypto-crime-surges/"
    },
    {
      "text": "Optimizing Data Transfer in Batched AI/ML Inference Workloads",
      "url": "https://towardsdatascience.com/optimizing-data-transfer-in-batched-ai-ml-inference-workloads/"
    },
    {
      "text": "How next-generation nuclear reactors break out of the 20th-century blueprint",
      "url": "https://www.technologyreview.com/2026/01/12/1129797/next-generation-nuclear-reactors-power-energy/"
    },
    {
      "text": "Good technology should change the world",
      "url": "https://www.technologyreview.com/2026/01/12/1129770/editors-letter-january-2026/"
    },
    {
      "text": "A Framework for Personalized Persuasiveness Prediction via Context-Aware User Profiling",
      "url": "https://arxiv.org/abs/2601.05654"
    }
  ],
  "rightColumn": [
    {
      "text": "RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models",
      "url": "https://arxiv.org/abs/2601.05451"
    },
    {
      "text": "MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization",
      "url": "https://arxiv.org/abs/2601.05475"
    },
    {
      "text": "Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion",
      "url": "https://arxiv.org/abs/2601.05629"
    },
    {
      "text": "HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation",
      "url": "https://arxiv.org/abs/2601.05656"
    },
    {
      "text": "MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding",
      "url": "https://arxiv.org/abs/2601.05495"
    },
    {
      "text": "Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors",
      "url": "https://arxiv.org/abs/2601.05508"
    },
    {
      "text": "Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts",
      "url": "https://arxiv.org/abs/2601.05537"
    },
    {
      "text": "RISE: Rule-Driven SQL Dialect Translation via Query Reduction",
      "url": "https://arxiv.org/abs/2601.05579"
    }
  ],
  "lastUpdated": "2026-01-13T04:06:59Z"
}