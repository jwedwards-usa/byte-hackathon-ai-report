{
  "mainHeadline": {
    "text": "Anthropic takes on OpenAI and Google with new Claude AI features designed for students and developers",
    "url": "https://venturebeat.com/ai/anthropic-takes-on-openai-and-google-with-new-claude-ai-features-designed-for-students-and-developers/"
  },
  "topStories": [
    {
      "text": "Towards data-centric interpretability with sparse autoencoders",
      "url": "https://www.lesswrong.com/posts/a4EDinzAYtRwpNmx9/towards-data-centric-interpretability-with-sparse"
    },
    {
      "text": "Anthropic has new rules for a more dangerous AI landscape",
      "url": "https://www.theverge.com/news/760080/anthropic-updated-usage-policy-dangerous-ai-landscape"
    },
    {
      "text": "Open weight LLMs exhibit inconsistent performance across providers",
      "url": "https://simonwillison.net/2025/Aug/15/inconsistent-performance/#atom-everything"
    }
  ],
  "leftColumn": [
    {
      "text": "The Download: Taiwan’s silicon shield, and ChatGPT’s personality misstep",
      "url": "https://www.technologyreview.com/2025/08/15/1121920/the-download-taiwans-silicon-shield-and-chatgpts-personality-misstep/"
    },
    {
      "text": "Evaluation of GPT-based large language generative AI models as study aids for the national licensure examination for registered dietitians in Japan",
      "url": "https://arxiv.org/abs/2508.10011"
    },
    {
      "text": "The head of ChatGPT on AI attachment, ads, and what’s next",
      "url": "https://www.theverge.com/decoder-podcast-with-nilay-patel/758873/chatgpt-nick-turley-openai-ai-gpt-5-interview"
    },
    {
      "text": "This researcher turned OpenAI’s open weights model gpt-oss-20b into a non-reasoning ‘base’ model with less alignment, more freedom",
      "url": "https://venturebeat.com/ai/this-researcher-turned-openais-open-weights-model-gpt-oss-20b-into-a-non-reasoning-base-model-with-less-alignment-more-freedom/"
    },
    {
      "text": "PERFORMANCE OF GPT-5 IN BRAIN TUMOR MRI REASONING",
      "url": "https://arxiv.org/abs/2508.10865"
    },
    {
      "text": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence",
      "url": "https://arxiv.org/abs/2508.10241"
    },
    {
      "text": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data",
      "url": "https://arxiv.org/abs/2508.10027"
    },
    {
      "text": "JAILBREAKING COMMERCIAL BLACK-BOX LLMS WITH EXPLICITLY HARMFUL PROMPTS",
      "url": "https://arxiv.org/abs/2508.10390"
    }
  ],
  "centerColumn": [
    {
      "text": "Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs",
      "url": "https://arxiv.org/abs/2508.10142"
    },
    {
      "text": "Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed",
      "url": "https://arxiv.org/abs/2406.04443"
    },
    {
      "text": "Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding",
      "url": "https://arxiv.org/abs/2508.10369"
    },
    {
      "text": "SoK: Data Minimization in Machine Learning",
      "url": "https://arxiv.org/abs/2508.10836"
    },
    {
      "text": "Evaluating LLMs on Chinese Idiom Translation",
      "url": "https://arxiv.org/abs/2508.10421"
    },
    {
      "text": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection and Dimensional Separation in Quantum Machine Learning",
      "url": "https://arxiv.org/abs/2508.10533"
    },
    {
      "text": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers",
      "url": "https://arxiv.org/abs/2508.10457"
    },
    {
      "text": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning",
      "url": "https://arxiv.org/abs/2508.10848"
    }
  ],
  "rightColumn": [
    {
      "text": "Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History",
      "url": "https://arxiv.org/abs/2508.10074"
    },
    {
      "text": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement",
      "url": "https://arxiv.org/abs/2508.10436"
    },
    {
      "text": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models",
      "url": "https://arxiv.org/abs/2503.23714"
    },
    {
      "text": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction",
      "url": "https://arxiv.org/abs/2508.10731"
    },
    {
      "text": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning",
      "url": "https://arxiv.org/abs/2508.10419"
    },
    {
      "text": "DINOv3",
      "url": "https://arxiv.org/abs/2508.10104"
    },
    {
      "text": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification",
      "url": "https://arxiv.org/abs/2508.10712"
    },
    {
      "text": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning",
      "url": "https://arxiv.org/abs/2508.09325"
    }
  ],
  "lastUpdated": "2025-08-15T21:19:56Z"
}