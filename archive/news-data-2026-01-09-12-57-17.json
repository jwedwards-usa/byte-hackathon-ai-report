{
  "mainHeadline": {
    "text": "Alignment Faking is a Linear Feature in Anthropic's Hughes Model",
    "url": "https://www.lesswrong.com/posts/TazJpnBnvPC5tJoWo/alignment-faking-is-a-linear-feature-in-anthropic-s-hughes"
  },
  "topStories": [
    {
      "text": "HOW GOOGLE GOT ITS GROOVE BACK AND EDGED AHEAD OF OPENAI",
      "url": "https://simonwillison.net/2026/Jan/8/how-google-got-its-groove-back/#atom-everything"
    },
    {
      "text": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
      "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in"
    },
    {
      "text": "Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training",
      "url": "https://arxiv.org/abs/2508.14904"
    }
  ],
  "leftColumn": [
    {
      "text": "The Economics of Transformative AI",
      "url": "https://www.lesswrong.com/posts/epFKhn24trRP2cs3k/the-economics-of-transformative-ai"
    },
    {
      "text": "Skepticism about Introspection in LLMs",
      "url": "https://www.lesswrong.com/posts/Yc9AH29h7wxpqY3vf/skepticism-about-introspection-in-llms"
    },
    {
      "text": "Automated Invoice Data Extraction: Using LLM and OCR",
      "url": "https://arxiv.org/abs/2511.05547"
    },
    {
      "text": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
      "url": "https://arxiv.org/abs/2601.05232"
    },
    {
      "text": "Vibe Coding an LLM-powered Theorem Prover",
      "url": "https://arxiv.org/abs/2601.04653"
    },
    {
      "text": "NorwAI's Large Language Models: Technical Report",
      "url": "https://arxiv.org/abs/2601.03034"
    },
    {
      "text": "Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication",
      "url": "https://arxiv.org/abs/2601.05084"
    },
    {
      "text": "Claude Code 2.1.0 arrives with smoother workflows and smarter agents",
      "url": "https://venturebeat.com/orchestration/claude-code-2-1-0-arrives-with-smoother-workflows-and-smarter-agents",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/VJOOEdM2W3XTpiKR09T2d/7c640966cb70007a9ea5a465637f38a9/nano_banana_removed.png?w=300\u0026q=30",
        "alt": "Claude Code 2.1.0 arrives with smoother workflows and smarter agents",
        "width": 600,
        "height": 400
      }
    }
  ],
  "centerColumn": [
    {
      "text": "Neural-Symbolic Integration with Evolvable Policies",
      "url": "https://arxiv.org/abs/2601.04799"
    },
    {
      "text": "Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models",
      "url": "https://arxiv.org/abs/2601.04751"
    },
    {
      "text": "Exploring the limits of strong membership inference attacks on large language models",
      "url": "https://arxiv.org/abs/2505.18773"
    },
    {
      "text": "Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization",
      "url": "https://arxiv.org/abs/2601.04582"
    },
    {
      "text": "Actively Obtaining Environmental Feedback for Autonomous Action Evaluation Without Predefined Measurements",
      "url": "https://arxiv.org/abs/2601.04235"
    },
    {
      "text": "Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?",
      "url": "https://arxiv.org/abs/2601.04690"
    },
    {
      "text": "A Future Capabilities Agent for Tactical Air Traffic Control",
      "url": "https://arxiv.org/abs/2601.04285"
    },
    {
      "text": "Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots",
      "url": "https://arxiv.org/abs/2504.16680"
    }
  ],
  "rightColumn": [
    {
      "text": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
      "url": "https://arxiv.org/abs/2601.05107"
    },
    {
      "text": "Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models",
      "url": "https://arxiv.org/abs/2601.05144"
    },
    {
      "text": "Inside Out: Evolving User-Centric Core Memory Trees for Long-Term Personalized Dialogue Systems",
      "url": "https://arxiv.org/abs/2601.05171"
    },
    {
      "text": "Reverse-engineering NLI: A study of the meta-inferential properties of Natural Language Inference",
      "url": "https://arxiv.org/abs/2601.05170"
    },
    {
      "text": "SemPA: Improving Sentence Embeddings of Large Language Models through Semantic Preference Alignment",
      "url": "https://arxiv.org/abs/2601.05075"
    },
    {
      "text": "A Unified Spoken Language Model with Injected Emotional-Attribution Thinking for Human-like Interaction",
      "url": "https://arxiv.org/abs/2601.04960"
    },
    {
      "text": "EvolSQL: Structure-Aware Evolution for Scalable Text-to-SQL Data Synthesis",
      "url": "https://arxiv.org/abs/2601.04875"
    },
    {
      "text": "A Navigational Approach for Comprehensive RAG via Traversal over Proposition Graphs",
      "url": "https://arxiv.org/abs/2601.04859"
    }
  ],
  "lastUpdated": "2026-01-09T12:57:17Z"
}