{
  "mainHeadline": {
    "text": "Automating Deception: Scalable Multi-Turn LLM Jailbreaks",
    "url": "https://arxiv.org/abs/2511.19517"
  },
  "topStories": [
    {
      "text": "MULTI-TURN JAILBREAKING ATTACK IN MULTI-MODAL LARGE LANGUAGE MODELS",
      "url": "https://arxiv.org/abs/2601.05339"
    },
    {
      "text": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction",
      "url": "https://arxiv.org/abs/2601.05266"
    },
    {
      "text": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset",
      "url": "https://arxiv.org/abs/2601.05918"
    }
  ],
  "leftColumn": [
    {
      "text": "KNOWLEDGE-DRIVEN MULTI-TURN JAILBREAKING ON LARGE LANGUAGE MODELS",
      "url": "https://arxiv.org/abs/2601.05445"
    },
    {
      "text": "Gender Bias in LLMs: Preliminary Evidence from Shared Parenting Scenario in Czech Family Law",
      "url": "https://arxiv.org/abs/2601.05879"
    },
    {
      "text": "JAILBREAKING LARGE LANGUAGE MODELS THROUGH ITERATIVE TOOL-DISGUISED ATTACKS VIA REINFORCEMENT LEARNING",
      "url": "https://arxiv.org/abs/2601.05466"
    },
    {
      "text": "Transforming User Defined Criteria into Explainable Indicators with an Integrated LLM AHP System",
      "url": "https://arxiv.org/abs/2601.05267"
    },
    {
      "text": "The Echo Chamber Multi-Turn LLM Jailbreak",
      "url": "https://arxiv.org/abs/2601.05742"
    },
    {
      "text": "GIFT: Games as Informal Training for Generalizable LLMs",
      "url": "https://arxiv.org/abs/2601.05633"
    },
    {
      "text": "Continual Pretraining on Encrypted Synthetic Data for Privacy-Preserving LLMs",
      "url": "https://arxiv.org/abs/2601.05635"
    },
    {
      "text": "On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis",
      "url": "https://arxiv.org/abs/2601.05280"
    }
  ],
  "centerColumn": [
    {
      "text": "An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift",
      "url": "https://arxiv.org/abs/2601.05882"
    },
    {
      "text": "Visual Attention Reasoning via Hierarchical Search and Self-Verification",
      "url": "https://arxiv.org/abs/2510.18619"
    },
    {
      "text": "DynaSTy: A Framework for SpatioTemporal Node Attribute Prediction in Dynamic Graphs",
      "url": "https://arxiv.org/abs/2601.05391"
    },
    {
      "text": "TDHook: A Lightweight Framework for Interpretability",
      "url": "https://arxiv.org/abs/2509.25475"
    },
    {
      "text": "Rethinking Supply Chain Planning: A Generative Paradigm",
      "url": "https://arxiv.org/abs/2509.03811"
    },
    {
      "text": "Imitation Learning for Combinatorial Optimisation under Uncertainty",
      "url": "https://arxiv.org/abs/2601.05383"
    },
    {
      "text": "SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning",
      "url": "https://arxiv.org/abs/2505.11274"
    },
    {
      "text": "Climbing the Ladder of Reasoning: What LLMs Can-and Still Can't-Solve after SFT?",
      "url": "https://arxiv.org/abs/2504.11741"
    }
  ],
  "rightColumn": [
    {
      "text": "Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems",
      "url": "https://arxiv.org/abs/2601.05264"
    },
    {
      "text": "FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse",
      "url": "https://arxiv.org/abs/2601.05505"
    },
    {
      "text": "CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems",
      "url": "https://arxiv.org/abs/2601.05520"
    },
    {
      "text": "Prophet as a Repro ducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics",
      "url": "https://arxiv.org/abs/2601.05929"
    },
    {
      "text": "Continual-learning for Modelling Low-Resource Languages from Large Language Models",
      "url": "https://arxiv.org/abs/2601.05874"
    },
    {
      "text": "Can Large Language Models Differentiate Harmful from Argumentative Essays? Steps Toward Ethical Essay Scoring",
      "url": "https://arxiv.org/abs/2601.05545"
    },
    {
      "text": "Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification",
      "url": "https://arxiv.org/abs/2601.05785"
    },
    {
      "text": "Can large language models interpret unstructured chat data on dynamic group decision-making processes? Evidence on joint destination choice",
      "url": "https://arxiv.org/abs/2601.05582"
    }
  ],
  "lastUpdated": "2026-01-12T09:40:23Z"
}