{
  "mainHeadline": {
    "text": "First impressions of Claude Cowork, Anthropic's general agent",
    "url": "https://simonwillison.net/2026/Jan/12/claude-cowork/#atom-everything"
  },
  "topStories": [
    {
      "text": "BlackBoxQuery [BBQ]-Bench: Measuring Hypothesis Formation and Experimentation Capabilities in LLMs",
      "url": "https://www.lesswrong.com/posts/fFuwW2nE5rZNSFQmY/blackboxquery-bbq-bench-measuring-hypothesis-formation-and-1"
    },
    {
      "text": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
      "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no"
    },
    {
      "text": "Automating Deception: Scalable Multi-Turn LLM Jailbreaks",
      "url": "https://arxiv.org/abs/2511.19517"
    }
  ],
  "leftColumn": [
    {
      "text": "Model Reduction as Interpretability: What Neuroscience Could Teach Us About Understanding Complex Systems",
      "url": "https://www.lesswrong.com/posts/9EZZDfo8ijBgDFy7A/model-reduction-as-interpretability-what-neuroscience-could-1"
    },
    {
      "text": "Anthropic wants you to use Claude to ‘Cowork’ in latest AI agent push",
      "url": "https://www.theverge.com/ai-artificial-intelligence/860730/anthropic-cowork-feature-ai-agents-claude-code"
    },
    {
      "text": "Attempting to influence transformer representations via initialization",
      "url": "https://www.lesswrong.com/posts/4nTDGhCT7nxrtLXdf/attempting-to-influence-transformer-representations-via"
    },
    {
      "text": "Tensor-Transformer Variants are Surprisingly Performant",
      "url": "https://www.lesswrong.com/posts/hp9bvkiN3RzHgP9cq/tensor-transformer-variants-are-surprisingly-performant"
    },
    {
      "text": "Brief Explorations in LLM Value Rankings",
      "url": "https://www.alignmentforum.org/posts/k6HKzwqCY4wKncRkM/brief-explorations-in-llm-value-rankings"
    },
    {
      "text": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction",
      "url": "https://arxiv.org/abs/2601.05266"
    },
    {
      "text": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset",
      "url": "https://arxiv.org/abs/2601.05918"
    },
    {
      "text": "MULTI-TURN JAILBREAKING ATTACK IN MULTI-MODAL LARGE LANGUAGE MODELS",
      "url": "https://arxiv.org/abs/2601.05339"
    }
  ],
  "centerColumn": [
    {
      "text": "LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection",
      "url": "https://arxiv.org/abs/2601.06016"
    },
    {
      "text": "UK pushes up a law criminalizing deepfake nudes in response to Grok",
      "url": "https://www.theverge.com/news/860881/uk-ai-x-grok-law-criminalizing-deepfake-nudes-ai"
    },
    {
      "text": "How AI Can Become Your Personal Language Tutor",
      "url": "https://towardsdatascience.com/how-ai-can-become-your-personal-language-tutor/"
    },
    {
      "text": "Securing digital assets as crypto crime surges",
      "url": "https://www.technologyreview.com/2026/01/12/1129479/securing-digital-assets-as-crypto-crime-surges/"
    },
    {
      "text": "Optimizing Data Transfer in Batched AI/ML Inference Workloads",
      "url": "https://towardsdatascience.com/optimizing-data-transfer-in-batched-ai-ml-inference-workloads/"
    },
    {
      "text": "How next-generation nuclear reactors break out of the 20th-century blueprint",
      "url": "https://www.technologyreview.com/2026/01/12/1129797/next-generation-nuclear-reactors-power-energy/"
    },
    {
      "text": "Good technology should change the world",
      "url": "https://www.technologyreview.com/2026/01/12/1129770/editors-letter-january-2026/"
    },
    {
      "text": "Imitation Learning for Combinatorial Optimisation under Uncertainty",
      "url": "https://arxiv.org/abs/2601.05383"
    }
  ],
  "rightColumn": [
    {
      "text": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck",
      "url": "https://arxiv.org/abs/2601.05870"
    },
    {
      "text": "UPDESH: Synthesizing Grounded Instruction Tuning Data for 13 Indic",
      "url": "https://arxiv.org/abs/2509.21294"
    },
    {
      "text": "Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning",
      "url": "https://arxiv.org/abs/2601.05474"
    },
    {
      "text": "Fine-tuning Done Right in Model Editing",
      "url": "https://arxiv.org/abs/2509.22072"
    },
    {
      "text": "Simulating Multi-Stakeholder Decision-Making with Generative Agents in Urban Planning",
      "url": "https://arxiv.org/abs/2402.11314"
    },
    {
      "text": "DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis",
      "url": "https://arxiv.org/abs/2601.05527"
    },
    {
      "text": "Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts",
      "url": "https://arxiv.org/abs/2601.05537"
    },
    {
      "text": "VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck",
      "url": "https://arxiv.org/abs/2601.05547"
    }
  ],
  "lastUpdated": "2026-01-13T02:03:13Z"
}