{
  "mainHeadline": {
    "text": "AI #126: Go Fund Yourself",
    "url": "https://www.lesswrong.com/posts/ygND532h4CotfPcp7/ai-126-go-fund-yourself"
  },
  "topStories": [
    {
      "text": "Cursory Analysis of LLMs in the US Gov (July 2025)",
      "url": "https://www.lesswrong.com/posts/Lojk2pMJhHrmANag3/cursory-analysis-of-llms-in-the-us-gov-july-2025"
    },
    {
      "text": "OPENAI PREPARES TO LAUNCH GPT-5 IN AUGUST",
      "url": "https://www.theverge.com/notepad-microsoft-newsletter/712950/openai-gpt-5-model-release-date-notepad"
    },
    {
      "text": "HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery",
      "url": "https://arxiv.org/abs/2507.17209"
    }
  ],
  "leftColumn": [
    {
      "text": "RESOLVING DIGITAL THREATS 100X FASTER WITH OPENAI",
      "url": "https://openai.com/index/outtake"
    },
    {
      "text": "Using GitHub Spark to reverse engineer GitHub Spark",
      "url": "https://simonwillison.net/2025/Jul/24/github-spark/#atom-everything"
    },
    {
      "text": "Taking Abundance Seriously",
      "url": "https://www.lesswrong.com/posts/XokWXdykGgewTxDFs/taking-abundance-seriously"
    },
    {
      "text": "Reflections from Ooty retreat 2.0",
      "url": "https://www.lesswrong.com/posts/KerjdwMehqrHDHEhJ/reflections-from-ooty-retreat-2-0"
    },
    {
      "text": "LLM as a code generator in Agile Model Driven Development",
      "url": "https://arxiv.org/abs/2410.18489"
    },
    {
      "text": "DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD",
      "url": "https://arxiv.org/abs/2507.17501"
    },
    {
      "text": "Leveraging Synthetic Data for Question Answering with Multilingual LLMs in the Agricultural Domain",
      "url": "https://arxiv.org/abs/2507.16974"
    },
    {
      "text": "Obscured but Not Erased: Evaluating Nationality Bias in LLMs via Name-Based Bias Benchmarks",
      "url": "https://arxiv.org/abs/2507.16989"
    }
  ],
  "centerColumn": [
    {
      "text": "Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems",
      "url": "https://arxiv.org/abs/2507.17061"
    },
    {
      "text": "Instagram Reel: Veo 3 paid preview",
      "url": "https://simonwillison.net/2025/Jul/23/instagram-reel-veo-3-paid-preview/#atom-everything"
    },
    {
      "text": "Introducing OSS Rebuild: Open Source, Rebuilt to Last",
      "url": "https://simonwillison.net/2025/Jul/23/oss-rebuild/#atom-everything"
    },
    {
      "text": "TimeScope: How Long Can Your Video Large Multimodal Model Go?",
      "url": "https://simonwillison.net/2025/Jul/23/timescope/#atom-everything"
    },
    {
      "text": "Announcing Toad - a universal UI for agentic coding in the terminal",
      "url": "https://simonwillison.net/2025/Jul/23/announcing-toad/#atom-everything"
    },
    {
      "text": "The Download: whatâ€™s next for AI agents, and how Trump protects US tech companies overseas",
      "url": "https://www.technologyreview.com/2025/07/23/1120571/the-download-whats-next-for-ai-agents-and-how-trump-protects-us-tech-companies-overseas/"
    },
    {
      "text": "Model ML is helping financial firms rebuild with AI from the ground up",
      "url": "https://openai.com/index/model-ml-chaz-englander"
    },
    {
      "text": "Qwen3-Coder: Agentic Coding in the World",
      "url": "https://simonwillison.net/2025/Jul/22/qwen3-coder/#atom-everything"
    }
  ],
  "rightColumn": [
    {
      "text": "HydraOpt: Navigating the Efficiency-Performance Trade-off of Adapter Merging",
      "url": "https://arxiv.org/abs/2507.17706"
    },
    {
      "text": "HIPPO-Video: Simulating Watch Histories with Large Language Models for Personalized Video Highlighting",
      "url": "https://arxiv.org/abs/2507.16873"
    },
    {
      "text": "Joint Asymmetric Loss for Learning with Noisy Labels",
      "url": "https://arxiv.org/abs/2507.17692"
    },
    {
      "text": "CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos",
      "url": "https://arxiv.org/abs/2507.16878"
    },
    {
      "text": "Towards Effective Open-set Graph Class-incremental Learning",
      "url": "https://arxiv.org/abs/2507.17687"
    },
    {
      "text": "Confidence Optimization for Probabilistic Encoding",
      "url": "https://arxiv.org/abs/2507.16881"
    },
    {
      "text": "XStacking: Explanation-Guided Stacked Ensemble Learning",
      "url": "https://arxiv.org/abs/2507.17650"
    },
    {
      "text": "Sensor Drift Compensation in Electronic-Nose-Based Gas Recognition Using Knowledge Distillation",
      "url": "https://arxiv.org/abs/2507.17071"
    }
  ],
  "lastUpdated": "2025-07-24T18:35:41Z"
}