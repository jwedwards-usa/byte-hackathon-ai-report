{
  "mainHeadline": {
    "text": "Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use",
    "url": "https://arxiv.org/abs/2512.23137"
  },
  "topStories": [
    {
      "text": "Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part II: Physics-Informed Neural Networks and Uncertainty Quantification",
      "url": "https://arxiv.org/abs/2512.22189"
    },
    {
      "text": "Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part I: Basic Concepts, Neural Networks, and Variants",
      "url": "https://arxiv.org/abs/2512.22190"
    },
    {
      "text": "AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents",
      "url": "https://arxiv.org/abs/2512.22387"
    }
  ],
  "leftColumn": [
    {
      "text": "ChatGPT-4 and other LLMs in the Turing Test: A Critical Analysis",
      "url": "https://arxiv.org/abs/2503.06551"
    },
    {
      "text": "The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?",
      "url": "https://arxiv.org/abs/2512.22625"
    },
    {
      "text": "AWARENESS JAILBREAKING: REVEALING TRUE ALIGNMENT IN EVALUATION-AWARE MODELS",
      "url": "https://www.lesswrong.com/posts/srEijciwxfWEisYqX/awareness-jailbreaking-revealing-true-alignment-in"
    },
    {
      "text": "LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training",
      "url": "https://arxiv.org/abs/2512.22264"
    },
    {
      "text": "Involuntary Jailbreak: On Self-Prompting Attacks",
      "url": "https://arxiv.org/abs/2508.13246"
    },
    {
      "text": "Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems",
      "url": "https://arxiv.org/abs/2512.23132"
    },
    {
      "text": "Anka: A Domain-Specific Language for Reliable LLM Code Generation",
      "url": "https://arxiv.org/abs/2512.23214"
    },
    {
      "text": "The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction",
      "url": "https://arxiv.org/abs/2512.23489"
    }
  ],
  "centerColumn": [
    {
      "text": "Parameter-Efficient and Personalized Federated Training of Generative Models at the Edge",
      "url": "https://arxiv.org/abs/2511.11585"
    },
    {
      "text": "Unleashing Foundation Vision Models: Adaptive Transfer for Diverse Data-Limited Scientific Domains",
      "url": "https://arxiv.org/abs/2512.22664"
    },
    {
      "text": "TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage",
      "url": "https://arxiv.org/abs/2308.03427"
    },
    {
      "text": "Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks",
      "url": "https://arxiv.org/abs/2512.23557"
    },
    {
      "text": "AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization",
      "url": "https://arxiv.org/abs/2512.23537"
    },
    {
      "text": "Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach",
      "url": "https://arxiv.org/abs/2512.17367"
    },
    {
      "text": "Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning",
      "url": "https://arxiv.org/abs/2512.22742"
    },
    {
      "text": "Theory of Mind for Explainable Human-Robot Interaction",
      "url": "https://arxiv.org/abs/2512.23482"
    }
  ],
  "rightColumn": [
    {
      "text": "FLEX-MoE: Federated Mixture-of-Experts with Load-balanced Expert Assignment",
      "url": "https://arxiv.org/abs/2512.23070"
    },
    {
      "text": "WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference",
      "url": "https://arxiv.org/abs/2512.22737"
    },
    {
      "text": "Reservoir Computing inspired Matrix Multiplication-free Language Model",
      "url": "https://arxiv.org/abs/2512.23145"
    },
    {
      "text": "Harnessing Large Language Models for Biomedical Named Entity Recognition",
      "url": "https://arxiv.org/abs/2512.22738"
    },
    {
      "text": "Hallucination Detection and Evaluation of Large Language Model",
      "url": "https://arxiv.org/abs/2512.22416"
    },
    {
      "text": "SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals",
      "url": "https://arxiv.org/abs/2512.23131"
    },
    {
      "text": "Principled Algorithms for Optimizing Generalized Metrics in Binary Classification",
      "url": "https://arxiv.org/abs/2512.23133"
    },
    {
      "text": "A Weak Signal Learning Dataset and Its Baseline Method",
      "url": "https://arxiv.org/abs/2512.23160"
    }
  ],
  "lastUpdated": "2025-12-30T06:42:06Z"
}