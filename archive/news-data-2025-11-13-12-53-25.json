{
  "mainHeadline": {
    "text": "Baidu just dropped an open-source multimodal AI that it claims beats GPT-5 and Gemini",
    "url": "https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5"
  },
  "topStories": [
    {
      "text": "OpenAI reboots ChatGPT experience with GPT-5.1 after mixed reviews of GPT-5",
      "url": "https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/3CpLfvpU0TfycKYEA3DBLw/f7dc8b8d4db1e3eef3d0b619d662879e/crimedy7_illustration_of_a_conversation_abstract_--ar_169_--v_5a880096-9873-4985-85ae-e8c247d831fc_0.png?w=300\u0026q=30",
        "alt": "OpenAI reboots ChatGPT experience with GPT-5.1 after mixed reviews of GPT-5",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "The Three Ages of Data Science: When to Use Traditional Machine Learning, Deep Learning, or a LLM (Explained with One Example)",
      "url": "https://towardsdatascience.com/the-three-ages-of-data-science-when-to-use-traditional-machine-learning-deep-learning-or-a-large-language-models-explained-with-one-example/"
    },
    {
      "text": "Weibo's new open source AI model VibeThinker-1.5B outperforms DeepSeek-R1 on $7,800 post-training budget",
      "url": "https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/4s7atIbhZpkjUNIE9NqvrE/de645440ccc36273944e9ba58f78fea7/ChatGPT_Image_Nov_12__2025__02_29_18_PM.png?w=300\u0026q=30",
        "alt": "Weibo's new open source AI model VibeThinker-1.5B outperforms DeepSeek-R1 on $7,800 post-training budget",
        "width": 600,
        "height": 400
      }
    }
  ],
  "leftColumn": [
    {
      "text": "OpenAI says the brand-new GPT-5.1 is ‘warmer’ and has more ‘personality’ options",
      "url": "https://www.theverge.com/news/802653/openai-gpt-5-1-upgrade-personality-presets"
    },
    {
      "text": "3D Guard-Layer: An Integrated Agentic AI Safety System for Edge Artificial Intelligence",
      "url": "https://arxiv.org/abs/2511.08842"
    },
    {
      "text": "NEURO DRIVES NATIONAL RETAIL WINS WITH CHATGPT BUSINESS",
      "url": "https://openai.com/index/neurogum"
    },
    {
      "text": "Google is still aiming for its “moonshot” 2030 energy goals",
      "url": "https://www.technologyreview.com/2025/11/13/1127896/google-energy-goals/"
    },
    {
      "text": "Leveraging Small LLMs for Argument Mining in Education: Argument Component Identification, Classification, and Assessment",
      "url": "https://arxiv.org/abs/2502.14389"
    },
    {
      "text": "GPT-5.1: A SMARTER, MORE CONVERSATIONAL CHATGPT",
      "url": "https://openai.com/index/gpt-5-1"
    },
    {
      "text": "Sample Blog Post",
      "url": "https://www.anthropic.com/news"
    },
    {
      "text": "Google Pixel and Golden Goose partner to  bring AI to global ateliers",
      "url": "https://blog.google/products/pixel/google-pixel-and-golden-goose-partner-to-bring-ai-to-global-ateliers/"
    }
  ],
  "centerColumn": [
    {
      "text": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework",
      "url": "https://arxiv.org/abs/2506.15538"
    },
    {
      "text": "Practical and Performant Enhancements for Maximization of Algebraic Connectivity",
      "url": "https://arxiv.org/abs/2511.08694"
    },
    {
      "text": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm",
      "url": "https://arxiv.org/abs/2511.09392"
    },
    {
      "text": "Diffusion-based Sinogram Interpolation for Limited Angle PET",
      "url": "https://arxiv.org/abs/2511.09383"
    },
    {
      "text": "Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier",
      "url": "https://arxiv.org/abs/2511.09332"
    },
    {
      "text": "Bayesian Mixture of Experts For Large Language Models",
      "url": "https://arxiv.org/abs/2511.08968"
    },
    {
      "text": "From Model Training to Model Raising - A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development",
      "url": "https://arxiv.org/abs/2511.09287"
    },
    {
      "text": "A Deep Learning-Based Method for Fully Coupled Non-Markovian FBSDEs with Applications",
      "url": "https://arxiv.org/abs/2511.08735"
    }
  ],
  "rightColumn": [
    {
      "text": "GenePheno: Interpretable Gene Knockout-Induced Phenotype Abnormality Prediction from Gene Sequences",
      "url": "https://arxiv.org/abs/2511.09512"
    },
    {
      "text": "Learning the Basis: A Kolmogorov-Arnold Network Approach Embedding Green's Function Priors",
      "url": "https://arxiv.org/abs/2511.08655"
    },
    {
      "text": "AutoSynth: Automated Workflow Optimization for High-Quality Synthetic Dataset Generation via Monte Carlo Tree Search",
      "url": "https://arxiv.org/abs/2511.09488"
    },
    {
      "text": "Learning Topology-Driven Multi-Subspace Fusion for Grassmannian Deep Network",
      "url": "https://arxiv.org/abs/2511.08628"
    },
    {
      "text": "PEGNet: A Physics-Embedded Graph Network for Long-Term Stable Multiphysics Simulation",
      "url": "https://arxiv.org/abs/2511.08697"
    },
    {
      "text": "Group Equivariance Meets Mechanistic Interpretability: Equivariant Sparse Autoencoders",
      "url": "https://arxiv.org/abs/2511.09432"
    },
    {
      "text": "Several Supporting Evidences for the Adaptive Feature Program",
      "url": "https://arxiv.org/abs/2511.09425"
    },
    {
      "text": "Enhancing PIBT via Multi-Action Operations",
      "url": "https://arxiv.org/abs/2511.09193"
    }
  ],
  "lastUpdated": "2025-11-13T12:53:25Z"
}