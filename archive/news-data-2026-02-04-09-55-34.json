{
  "mainHeadline": {
    "text": "Apple integrates Anthropic’s Claude and OpenAI’s Codex into Xcode 26.3 in push for ‘agentic coding’",
    "url": "https://venturebeat.com/technology/apple-integrates-anthropics-claude-and-openais-codex-into-xcode-26-3-in-push"
  },
  "topStories": [
    {
      "text": "OpenAI launches a Codex desktop app for macOS to run multiple AI coding agents in parallel",
      "url": "https://venturebeat.com/orchestration/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding"
    },
    {
      "text": "JAILBREAKING LLMS VIA CALIBRATION",
      "url": "https://arxiv.org/abs/2602.00619"
    },
    {
      "text": "AI Safety at the Frontier: Paper Highlights of January 2026",
      "url": "https://www.lesswrong.com/posts/JcAm6MFog6ssKooFN/ai-safety-at-the-frontier-paper-highlights-of-january-2026"
    }
  ],
  "leftColumn": [
    {
      "text": "Anthropic’s “Hot Mess” paper overstates its case (and the blog post is worse)",
      "url": "https://www.lesswrong.com/posts/ceEgAEXcL7cC2Ddiy/anthropic-s-hot-mess-paper-overstates-its-case-and-the-blog"
    },
    {
      "text": "Uncertainty and Fairness Awareness in LLM-Based Recommendation Systems",
      "url": "https://arxiv.org/abs/2602.02582"
    },
    {
      "text": "A Positive Case for Faithfulness: LLM Self-Explanations Help Predict Model Behavior",
      "url": "https://arxiv.org/abs/2602.02639"
    },
    {
      "text": "When LLMs Imagine People: A Human-Centered Persona Brainstorm Audit for Bias and Fairness in Creative Applications",
      "url": "https://arxiv.org/abs/2602.00044"
    },
    {
      "text": "Plain Transformers are Surprisingly Powerful Link Predictors",
      "url": "https://arxiv.org/abs/2602.01553"
    },
    {
      "text": "GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds",
      "url": "https://arxiv.org/abs/2601.13570"
    },
    {
      "text": "Noise-Adaptive Layerwise Learning Rates: Accelerating Geometry-Aware Optimization for Deep Neural Network Training",
      "url": "https://arxiv.org/abs/2510.14009"
    },
    {
      "text": "A Black Box Made Less Opaque (part 2)",
      "url": "https://www.lesswrong.com/posts/Qnm6gAFnCPaJsbhSS/a-black-box-made-less-opaque-part-2"
    }
  ],
  "centerColumn": [
    {
      "text": "FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution",
      "url": "https://arxiv.org/abs/2602.00948"
    },
    {
      "text": "DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning",
      "url": "https://arxiv.org/abs/2602.00983"
    },
    {
      "text": "Sheaf Neural Networks and biomedical applications",
      "url": "https://arxiv.org/abs/2602.00159"
    },
    {
      "text": "ProDCARL: Reinforcement Learning-Aligned Diffusion Models for De Novo Antimicrobial Peptide Design",
      "url": "https://arxiv.org/abs/2602.00157"
    },
    {
      "text": "HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving",
      "url": "https://arxiv.org/abs/2602.00993"
    },
    {
      "text": "Multi-Agent Teams Hold Experts Back",
      "url": "https://arxiv.org/abs/2602.01011"
    },
    {
      "text": "SITUATE -- Synthetic Object Counting Dataset for VLM training",
      "url": "https://arxiv.org/abs/2602.00108"
    },
    {
      "text": "Entropy-Gated Selective Policy Optimization:Token-Level Gradient Allocation for Hybrid Training of Large Language Models",
      "url": "https://arxiv.org/abs/2602.03309"
    }
  ],
  "rightColumn": [
    {
      "text": "MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers",
      "url": "https://arxiv.org/abs/2602.00933"
    },
    {
      "text": "The Label Horizon Paradox: Rethinking Supervision Targets in Financial Forecasting",
      "url": "https://arxiv.org/abs/2602.03395"
    },
    {
      "text": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models",
      "url": "https://arxiv.org/abs/2602.03392"
    },
    {
      "text": "Multimodal Scientific Learning Beyond Diffusions and Flows",
      "url": "https://arxiv.org/abs/2602.00960"
    },
    {
      "text": "GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability",
      "url": "https://arxiv.org/abs/2602.00979"
    },
    {
      "text": "Structure-Preserving Learning Improves Geometry Generalization in Neural PDEs",
      "url": "https://arxiv.org/abs/2602.02788"
    },
    {
      "text": "A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention",
      "url": "https://arxiv.org/abs/2602.01763"
    },
    {
      "text": "Causal Graph Learning via Distributional Invariance of Cause-Effect Relationship",
      "url": "https://arxiv.org/abs/2602.03353"
    }
  ],
  "lastUpdated": "2026-02-04T09:55:34Z"
}