{
  "mainHeadline": {
    "text": "The Alignment Problem Isn't Theoretical",
    "url": "https://www.lesswrong.com/posts/TKTijrrwtEFytAbhh/the-alignment-problem-isn-t-theoretical"
  },
  "topStories": [
    {
      "text": "OPENAI IS TRYING TO CLAMP DOWN ON ‘BIAS’ IN CHATGPT",
      "url": "https://www.theverge.com/news/798388/openai-chatgpt-political-bias-eval"
    },
    {
      "text": "Dr Evil \u0026 Realpolitik",
      "url": "https://www.lesswrong.com/posts/kCNr9qmyyYewoFF8p/dr-evil-and-realpolitik"
    },
    {
      "text": "How do we know when something is deserving of welfare?",
      "url": "https://www.lesswrong.com/posts/NYDFJFvGvunJLdvQY/how-do-we-know-when-something-is-deserving-of-welfare"
    }
  ],
  "leftColumn": [
    {
      "text": "OpenAI allegedly sent police to an AI regulation advocate’s door",
      "url": "https://www.theverge.com/news/798523/openai-ai-regulation-advocates-subpoenas-police"
    },
    {
      "text": "Sample Blog Post",
      "url": "https://www.anthropic.com/news"
    },
    {
      "text": "When dirt meets data: ScottsMiracle-Gro saved $150M using AI",
      "url": "https://venturebeat.com/ai/when-dirt-meets-data-scottsmiracle-gro",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/7d0hJ4qtWTk5GaypvPfHJY/53aa8c26a39b5f10e16b3073dd73a388/videoframe_878.png",
        "alt": "When dirt meets data: ScottsMiracle-Gro saved $150M using AI",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "The Narcissistic Spectrum",
      "url": "https://www.lesswrong.com/posts/tHrxTREAeck46TSqH/the-narcissistic-spectrum"
    },
    {
      "text": "Police are asking kids to stop pulling AI homeless man prank",
      "url": "https://www.theverge.com/news/798681/police-stop-pulling-ai-homeless-man-tiktok-prank"
    },
    {
      "text": "International Programme on AI Evaluations",
      "url": "https://www.lesswrong.com/posts/c5dSmRk4HfQqGH6ST/international-programme-on-ai-evaluations"
    },
    {
      "text": "Claude Code sub-agents",
      "url": "https://simonwillison.net/2025/Oct/11/sub-agents/#atom-everything"
    },
    {
      "text": "Is vibe coding ruining a generation of engineers?",
      "url": "https://venturebeat.com/ai/is-vibe-coding-ruining-a-generation-of-engineers",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/6O2FgBkLOdYG0bQrbbceee/70c01c9a6f6498e1888781c6ec759dd8/Junior_coders.png",
        "alt": "Is vibe coding ruining a generation of engineers?",
        "width": 600,
        "height": 400
      }
    }
  ],
  "centerColumn": [
    {
      "text": "simonw/claude-skills",
      "url": "https://simonwillison.net/2025/Oct/10/claude-skills/#atom-everything"
    },
    {
      "text": "Video of GPT-OSS 20B running on a phone",
      "url": "https://simonwillison.net/2025/Oct/10/gpt-oss-20b-snapdragon/#atom-everything"
    },
    {
      "text": "Designing for perpetual control",
      "url": "https://www.lesswrong.com/posts/Lsh3oHHRBDWSCtKLq/designing-for-perpetual-control"
    },
    {
      "text": "Subscribe to my Inkhaven feed!",
      "url": "https://www.lesswrong.com/posts/TkpFRLMHnQrj3bc7k/subscribe-to-my-inkhaven-feed"
    },
    {
      "text": "Quoting Slashdot",
      "url": "https://simonwillison.net/2025/Oct/12/slashdot/#atom-everything"
    },
    {
      "text": "How long do AI companies have to achieve significant capability gains before funding collapses?",
      "url": "https://www.lesswrong.com/posts/TiDF8JGEbZdh2Awax/how-long-do-ai-companies-have-to-achieve-significant"
    },
    {
      "text": "Vibing a Non-Trivial Ghostty Feature",
      "url": "https://simonwillison.net/2025/Oct/11/vibing-a-non-trivial-ghostty-feature/#atom-everything"
    },
    {
      "text": "Superpowers: How I'm using coding agents in October 2025",
      "url": "https://simonwillison.net/2025/Oct/10/superpowers/#atom-everything"
    }
  ],
  "rightColumn": [
    {
      "text": "Hollywood has no idea what to do about AI",
      "url": "https://www.theverge.com/ai-artificial-intelligence/798496/hollywood-openai-training-netflix-paramount-warner"
    },
    {
      "text": "Non-copyability as a security feature",
      "url": "https://www.lesswrong.com/posts/bLnGWNryvJHdvvxpa/non-copyability-as-a-security-feature"
    },
    {
      "text": "Faster LLM inference",
      "url": "https://www.together.ai/blog/adaptive-learning-speculator-system-atlas"
    },
    {
      "text": "Building Transformer Models from Scratch with PyTorch (10-day Mini-Course)",
      "url": "https://machinelearningmastery.com/building-transformer-models-from-scratch-with-pytorch-10-day-mini-course/"
    },
    {
      "text": "I wasn't confused by Thermodynamics",
      "url": "https://www.lesswrong.com/posts/MfiAsJWZMLQ4af9rt/i-wasn-t-confused-by-thermodynamics"
    },
    {
      "text": "A Retrospective Survey of 2024/2025 Open Source Supply Chain Compromises",
      "url": "https://simonwillison.net/2025/Oct/10/a-retrospective-survey/#atom-everything"
    },
    {
      "text": "Note on 11th October 2025",
      "url": "https://simonwillison.net/2025/Oct/11/uncomfortable/#atom-everything"
    },
    {
      "text": "A small number of samples can poison LLMs of any size",
      "url": "https://www.anthropic.com/research/small-samples-poison"
    }
  ],
  "lastUpdated": "2025-10-12T18:29:08Z"
}