{
  "mainHeadline": {
    "text": "Anthropic's Claude Opus 4.6 brings 1M token context and 'agent teams' to take on OpenAI's Codex",
    "url": "https://venturebeat.com/technology/anthropics-claude-opus-4-6-brings-1m-token-context-and-agent-teams-to-take"
  },
  "topStories": [
    {
      "text": "OpenAI’s GPT-5.3-Codex drops as Anthropic upgrades Claude — AI coding wars heat up ahead of Super Bowl ads",
      "url": "https://venturebeat.com/technology/openais-gpt-5-3-codex-drops-as-anthropic-upgrades-claude-ai-coding-wars-heat"
    },
    {
      "text": "AI #154: Claw Your Way To The Top",
      "url": "https://www.lesswrong.com/posts/AMLLKDzjohCNbrA6t/ai-154-claw-your-way-to-the-top"
    },
    {
      "text": "The nature of LLM algorithmic progress",
      "url": "https://www.lesswrong.com/posts/sGNFtWbXiLJg2hLzK/the-nature-of-llm-algorithmic-progress"
    }
  ],
  "leftColumn": [
    {
      "text": "Beyond the lakehouse: Fundamental's NEXUS bypasses manual ETL with a native foundation model for tabular data",
      "url": "https://venturebeat.com/technology/fundamental-emerges-from-stealth-with-first-major-foundation-model-trained",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/xQAJrXCEqJVZZ8XR58deG/1ee37fb8b0f2e5073789a90cd3349caa/3TAB6GEYAOuK63Z49gVbh_7rJTLGX7.png?w=300\u0026q=30",
        "alt": "Beyond the lakehouse: Fundamental's NEXUS bypasses manual ETL with a native foundation model for tabular data",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "Helping AI agents search to get the best results out of large language models",
      "url": "https://news.mit.edu/2026/helping-ai-agents-search-to-get-best-results-from-llms-0205"
    },
    {
      "text": "Agent Economics: a BOTEC on feasibility",
      "url": "https://www.lesswrong.com/posts/NqNmNqtQCaqtpAeyX/agent-economics-a-botec-on-feasibility"
    },
    {
      "text": "AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents",
      "url": "https://arxiv.org/abs/2512.22387"
    },
    {
      "text": "INTRODUCING OPENAI FRONTIER",
      "url": "https://openai.com/index/introducing-openai-frontier"
    },
    {
      "text": "Opus 4.6 and Codex 5.3",
      "url": "https://simonwillison.net/2026/Feb/5/two-new-models/#atom-everything"
    },
    {
      "text": "Preparing for a Warning Shot",
      "url": "https://www.lesswrong.com/posts/GKtwwqusm4vxqkChc/preparing-for-a-warning-shot"
    },
    {
      "text": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem",
      "url": "https://arxiv.org/abs/2602.03969"
    }
  ],
  "centerColumn": [
    {
      "text": "Topology-Aware Revival for Efficient Sparse Training",
      "url": "https://arxiv.org/abs/2602.04166"
    },
    {
      "text": "Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference",
      "url": "https://arxiv.org/abs/2602.03949"
    },
    {
      "text": "ZKBoost: Zero-Knowledge Verifiable Training for XGBoost",
      "url": "https://arxiv.org/abs/2602.04113"
    },
    {
      "text": "Attack-Resistant Uniform Fairness for Linear and Smooth Contextual Bandits",
      "url": "https://arxiv.org/abs/2602.04125"
    },
    {
      "text": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
      "url": "https://arxiv.org/abs/2602.04208"
    },
    {
      "text": "Language Models Struggle to Use Representations Learned In-Context",
      "url": "https://arxiv.org/abs/2602.04212"
    },
    {
      "text": "SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?",
      "url": "https://arxiv.org/abs/2602.03916"
    },
    {
      "text": "Byzantine Machine Learning: MultiKrum and an optimal notion of robustness",
      "url": "https://arxiv.org/abs/2602.03899"
    }
  ],
  "rightColumn": [
    {
      "text": "Knowledge Distillation for mmWave Beam Prediction Using Sub-6 GHz Channels",
      "url": "https://arxiv.org/abs/2602.04703"
    },
    {
      "text": "Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation",
      "url": "https://arxiv.org/abs/2602.03892"
    },
    {
      "text": "Entropy-Aware Structural Alignment for Zero-Shot Handwritten Chinese Character Recognition",
      "url": "https://arxiv.org/abs/2602.03913"
    },
    {
      "text": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish",
      "url": "https://arxiv.org/abs/2602.04492"
    },
    {
      "text": "Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science",
      "url": "https://arxiv.org/abs/2602.03915"
    },
    {
      "text": "Linguistic Blind Spots in Clinical Decision Extraction",
      "url": "https://arxiv.org/abs/2602.03942"
    },
    {
      "text": "Fixed Budget is No Harder Than Fixed Confidence in Best-Arm Identification up to Logarithmic Factors",
      "url": "https://arxiv.org/abs/2602.03972"
    },
    {
      "text": "Static and auto-regressive neural emulation of phytoplankton biomass dynamics from physical predictors in the global ocean",
      "url": "https://arxiv.org/abs/2602.04689"
    }
  ],
  "lastUpdated": "2026-02-05T21:39:14Z"
}