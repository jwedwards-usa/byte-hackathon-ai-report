{
  "mainHeadline": {
    "text": "Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text",
    "url": "https://arxiv.org/abs/2509.20375"
  },
  "topStories": [
    {
      "text": "OpenAI really, really wants you to start your day with ChatGPT Pulse",
      "url": "https://www.theverge.com/ai-artificial-intelligence/785881/openai-really-really-wants-you-to-start-your-day-with-chatgpt-pulse"
    },
    {
      "text": "The AI Village in Numbers",
      "url": "https://www.lesswrong.com/posts/KmH83cDTh54EjTjbi/the-ai-village-in-numbers"
    },
    {
      "text": "Widening AI Safety's talent pipeline by meeting people where they are",
      "url": "https://www.lesswrong.com/posts/x6ffKSHXxxbueYrHE/widening-ai-safety-s-talent-pipeline-by-meeting-people-where"
    }
  ],
  "leftColumn": [
    {
      "text": "Google AI Pro and Ultra subscribers now get Gemini CLI and Gemini Code Assist with higher limits.",
      "url": "https://blog.google/technology/developers/gemini-cli-code-assist-higher-limits/"
    },
    {
      "text": "Constrained Belief Updates and Geometric Structures in Transformer Representations for the RRXOR Process",
      "url": "https://www.lesswrong.com/posts/BRiQ6Mn5HKc5SoyY3/constrained-belief-updates-and-geometric-structures-in"
    },
    {
      "text": "Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis",
      "url": "https://arxiv.org/abs/2509.20768"
    },
    {
      "text": "BREAKING THE EXPLORATION BOTTLENECK: RUBRIC-SCAFFOLDED REINFORCEMENT LEARNING FOR GENERAL LLM REASONING",
      "url": "https://arxiv.org/abs/2508.16949"
    },
    {
      "text": "Embodied AI: From LLMs to World Models",
      "url": "https://arxiv.org/abs/2509.20021"
    },
    {
      "text": "CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain",
      "url": "https://arxiv.org/abs/2509.19925"
    },
    {
      "text": "Feedback request: Is the time right for an AI Safety stack exchange?",
      "url": "https://www.lesswrong.com/posts/qFKH5jhfKpcreCTkt/feedback-request-is-the-time-right-for-an-ai-safety-stack"
    },
    {
      "text": "Bias Similarity Measurement: A Black-Box Audit of Fairness Across LLMs",
      "url": "https://arxiv.org/abs/2410.12010"
    }
  ],
  "centerColumn": [
    {
      "text": "Predicting LLM Reasoning Performance with Small Proxy Model",
      "url": "https://arxiv.org/abs/2509.21013"
    },
    {
      "text": "Human Activity Recognition Based on Electrocardiogram Data Only",
      "url": "https://arxiv.org/abs/2509.19328"
    },
    {
      "text": "A systematic review of trial-matching pipelines using large language models",
      "url": "https://arxiv.org/abs/2509.19327"
    },
    {
      "text": "Online Adaptation via Dual-Stage Alignment and Self-Supervision for Fast-Calibration Brain-Computer Interfaces",
      "url": "https://arxiv.org/abs/2509.19403"
    },
    {
      "text": "Auto-Regressive U-Net for Full-Field Prediction of Shrinkage-Induced Damage in Concrete",
      "url": "https://arxiv.org/abs/2509.20507"
    },
    {
      "text": "TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding",
      "url": "https://arxiv.org/abs/2509.19406"
    },
    {
      "text": "Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel Contrastive Loss and Multimodal Learning",
      "url": "https://arxiv.org/abs/2509.19315"
    },
    {
      "text": "Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias",
      "url": "https://arxiv.org/abs/2509.19314"
    }
  ],
  "rightColumn": [
    {
      "text": "Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models",
      "url": "https://arxiv.org/abs/2509.20939"
    },
    {
      "text": "FracAug: Fractional Augmentation boost Graph-level Anomaly Detection under Limited Supervision",
      "url": "https://arxiv.org/abs/2509.20978"
    },
    {
      "text": "Toward Robust and Efficient ML-Based GPU Caching for Modern Inference",
      "url": "https://arxiv.org/abs/2509.20979"
    },
    {
      "text": "Pluralistic Off-policy Evaluation and Alignment",
      "url": "https://arxiv.org/abs/2509.19333"
    },
    {
      "text": "Feature Augmentation of GNNs for ILPs: Local Uniqueness Suffices",
      "url": "https://arxiv.org/abs/2509.21000"
    },
    {
      "text": "A Simple \"Motivation\" Can Enhance Reinforcement Finetuning of Large Reasoning Models",
      "url": "https://arxiv.org/abs/2506.18485"
    },
    {
      "text": "Quantifying Compositionality of Classic and State-of-the-Art Embeddings",
      "url": "https://arxiv.org/abs/2509.19332"
    },
    {
      "text": "ARF-RLHF: Adaptive Reward-Following for RLHF through Emotion-Driven Self-Supervision and Trace-Biased Dynamic Optimization",
      "url": "https://arxiv.org/abs/2507.03069"
    }
  ],
  "lastUpdated": "2025-09-26T15:23:28Z"
}