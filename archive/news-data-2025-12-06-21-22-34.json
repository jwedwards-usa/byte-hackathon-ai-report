{
  "mainHeadline": {
    "text": "OpenAI’s GPT-5.2 ‘code red’ response to Google is coming next week",
    "url": "https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response"
  },
  "topStories": [
    {
      "text": "Crazy ideas in AI Safety part 1: Easy Measurable Communication ",
      "url": "https://www.lesswrong.com/posts/YGBaJ6fmHRwEbAmwD/crazy-ideas-in-ai-safety-part-1-easy-measurable"
    },
    {
      "text": "AI Mood Ring: A Window Into LLM Emotions",
      "url": "https://www.lesswrong.com/posts/A5Byr2jkBJpnBdx23/ai-mood-ring-a-window-into-llm-emotions"
    },
    {
      "text": "AI denial is becoming an enterprise risk: Why dismissing “slop” obscures real capability gains",
      "url": "https://venturebeat.com/ai/ai-denial-is-becoming-an-enterprise-risk-why-dismissing-slop-obscures-real",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/4cm8F6jnq7mT7NhyXWA1qQ/119d505338624d93ce9134238ebe73d3/Denialism.png?w=300\u0026q=30",
        "alt": "AI denial is becoming an enterprise risk: Why dismissing “slop” obscures real capability gains",
        "width": 600,
        "height": 400
      }
    }
  ],
  "leftColumn": [
    {
      "text": "The 'truth serum' for AI: OpenAI’s new method for training models to confess their mistakes",
      "url": "https://venturebeat.com/ai/the-truth-serum-for-ai-openais-new-method-for-training-models-to-confess"
    },
    {
      "text": "Sample Blog Post",
      "url": "https://www.anthropic.com/news"
    },
    {
      "text": "Existential despair, with hope",
      "url": "https://www.lesswrong.com/posts/CeAtrFiNbHSawxTLG/existential-despair-with-hope"
    },
    {
      "text": "The Unexpected Effectiveness of One-Shot Decompilation with Claude",
      "url": "https://simonwillison.net/2025/Dec/6/one-shot-decompilation/#atom-everything"
    },
    {
      "text": "The corrigibility basin of attraction is a misleading gloss",
      "url": "https://www.lesswrong.com/posts/oLbpfPkdtcknABvvw/the-corrigibility-basin-of-attraction-is-a-misleading-gloss"
    },
    {
      "text": "An Ambitious Vision for Interpretability",
      "url": "https://www.alignmentforum.org/posts/Hy6PX43HGgmfiTaKu/an-ambitious-vision-for-interpretability"
    },
    {
      "text": "Gemini 3 Pro: the frontier of vision AI",
      "url": "https://blog.google/technology/developers/gemini-3-pro-vision/"
    },
    {
      "text": "IT’S CODE RED FOR CHATGPT",
      "url": "https://www.theverge.com/podcast/838932/openai-chatgpt-code-red-vergecast"
    }
  ],
  "centerColumn": [
    {
      "text": "I Need Your Help",
      "url": "https://www.lesswrong.com/posts/MK2R22usPbkihr52i/i-need-your-help"
    },
    {
      "text": "AI ‘creators’ might just crash the influencer economy",
      "url": "https://www.theverge.com/entertainment/839494/ai-literacy-tiktok"
    },
    {
      "text": "The Machine Learning “Advent Calendar” Day 6: Decision Tree Regressor",
      "url": "https://towardsdatascience.com/the-machine-learning-advent-calendar-day-6-decision-tree-regressor/"
    },
    {
      "text": "LW Transcendence",
      "url": "https://www.lesswrong.com/posts/GzHgKKpc7zKmKJf9k/lw-transcendence"
    },
    {
      "text": "Answering a child's questions",
      "url": "https://www.lesswrong.com/posts/bWJfniJ9kqsp5behg/answering-a-child-s-questions"
    },
    {
      "text": "Critical Meditation Theory",
      "url": "https://www.lesswrong.com/posts/Nwkzggk49Fq6knb9t/critical-meditation-theory"
    },
    {
      "text": "Tools, Agents, and Sycophantic Things",
      "url": "https://www.lesswrong.com/posts/o3LzMRdCebbpLfYgZ/tools-agents-and-sycophantic-things"
    },
    {
      "text": "The Machine Learning “Advent Calendar” Day 5: GMM in Excel",
      "url": "https://towardsdatascience.com/the-machine-learning-advent-calendar-day-5-gmm-in-excel/"
    }
  ],
  "rightColumn": [
    {
      "text": "The Adequacy of Class Separation",
      "url": "https://www.lesswrong.com/posts/7TCA6dDZDZ9ESPtaJ/the-adequacy-of-class-separation"
    },
    {
      "text": "Robots that spare warehouse workers the heavy lifting",
      "url": "https://news.mit.edu/2025/robots-spare-warehouse-workers-heavy-lifting-1205"
    },
    {
      "text": "We gave 5 LLMs $100K to trade stocks for 8 months",
      "url": "https://www.aitradearena.com/research/we-ran-llms-for-8-months"
    },
    {
      "text": "The New York Times sues Perplexity for producing ‘verbatim’ copies of its work",
      "url": "https://www.theverge.com/news/839006/new-york-times-perplexity-lawsuit-copyright"
    },
    {
      "text": "YOLOv1 Paper Walkthrough: The Day YOLO First Saw the World",
      "url": "https://towardsdatascience.com/yolov1-paper-walkthrough-the-day-yolo-first-saw-the-world/"
    },
    {
      "text": "Waymo’s robotaxis are under investigation for passing stopped school buses",
      "url": "https://www.theverge.com/news/838879/waymo-school-buses-probe"
    },
    {
      "text": "On the Challenge of Converting TensorFlow Models to PyTorch",
      "url": "https://towardsdatascience.com/on-the-challenge-of-converting-tensorflow-models-to-pytorch/"
    },
    {
      "text": "Thoughts on Go vs. Rust vs. Zig",
      "url": "https://simonwillison.net/2025/Dec/5/go-vs-rust-vs-zig/#atom-everything"
    }
  ],
  "lastUpdated": "2025-12-06T21:22:34Z"
}