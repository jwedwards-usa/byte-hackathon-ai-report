{
  "mainHeadline": {
    "text": "OpenClaw proves agentic AI works. It also proves your security model doesn't. 180,000 developers just made that your problem.",
    "url": "https://venturebeat.com/security/openclaw-agentic-ai-security-risk-ciso-guide"
  },
  "topStories": [
    {
      "text": "Background to Claude's uncertainty about phenomenal consciousness",
      "url": "https://www.lesswrong.com/posts/YFaqHpfjSwab9hFHD/background-to-claude-s-uncertainty-about-phenomenal"
    },
    {
      "text": "An explainable vision transformer with transfer learning based efficient drought stress identification",
      "url": "https://arxiv.org/abs/2407.21666"
    },
    {
      "text": "Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond",
      "url": "https://arxiv.org/abs/2601.21767"
    }
  ],
  "leftColumn": [
    {
      "text": "Senior Researcher - MIT AI Risk Initiative",
      "url": "https://www.lesswrong.com/posts/miMetJGhsGBEyxJFe/senior-researcher-mit-ai-risk-initiative"
    },
    {
      "text": "Monitoring benchmark for AI control",
      "url": "https://www.lesswrong.com/posts/X8qTKsGcnsTFrqM96/monitoring-benchmark-for-ai-control"
    },
    {
      "text": "Forecast: Recursively Self-improving AI for 2033",
      "url": "https://www.lesswrong.com/posts/GHxWxRFto32jedmJh/forecast-recursively-self-improving-ai-for-2033"
    },
    {
      "text": "Fairy2i: Training Complex LLMs from Real LLMs with All Parameters in $\\{\\pm 1, \\pm i\\}$",
      "url": "https://arxiv.org/abs/2512.02901"
    },
    {
      "text": "DBELLQUANT: BREAKING THE BELL WITH DOUBLE-BELL TRANSFORMATION FOR LLMS POST TRAINING BINARIZATION",
      "url": "https://arxiv.org/abs/2507.01027"
    },
    {
      "text": "A Unified XAI-LLM Approach for EndotrachealSuctioning Activity Recognition",
      "url": "https://arxiv.org/abs/2601.21802"
    },
    {
      "text": "Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text",
      "url": "https://arxiv.org/abs/2601.21895"
    },
    {
      "text": "Bridging On-Device and Cloud LLMs for Collaborative Reasoning: A Unified Methodology for Local Routing and Post-Training",
      "url": "https://arxiv.org/abs/2509.24050"
    }
  ],
  "centerColumn": [
    {
      "text": "Theoretically Optimal Attention/FFN Ratios in Disaggregated LLM Serving",
      "url": "https://arxiv.org/abs/2601.21351"
    },
    {
      "text": "Managing Solution Stability in Decision-Focused Learning with Cost Regularization",
      "url": "https://arxiv.org/abs/2601.21883"
    },
    {
      "text": "LoRIF: Low-Rank Influence Functions for Scalable Training Data Attribution",
      "url": "https://arxiv.org/abs/2601.21929"
    },
    {
      "text": "EnsembleLink: Accurate Record Linkage Without Training Data",
      "url": "https://arxiv.org/abs/2601.21138"
    },
    {
      "text": "Unifying Speech Editing Detection and Content Localization via Prior-Enhanced Audio LLMs",
      "url": "https://arxiv.org/abs/2601.21463"
    },
    {
      "text": "Self-Improving Pretraining: using post-trained models to pretrain better models",
      "url": "https://arxiv.org/abs/2601.21343"
    },
    {
      "text": "Adaptive Confidence Gating in Multi-Agent Collaboration for Efficient and Optimized Code Generation",
      "url": "https://arxiv.org/abs/2601.21469"
    },
    {
      "text": "Epistemic Uncertainty Quantification for Pre-trained VLMs via Riemannian Flow Matching",
      "url": "https://arxiv.org/abs/2601.21662"
    }
  ],
  "rightColumn": [
    {
      "text": "Scalable Linearized Laplace Approximation via Surrogate Neural Kernel",
      "url": "https://arxiv.org/abs/2601.21835"
    },
    {
      "text": "FISMO: Fisher-Structured Momentum-Orthogonalized Optimizer",
      "url": "https://arxiv.org/abs/2601.21750"
    },
    {
      "text": "Differentiable Knapsack and Top-k Operators via Dynamic Programming",
      "url": "https://arxiv.org/abs/2601.21775"
    },
    {
      "text": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
      "url": "https://arxiv.org/abs/2601.21181"
    },
    {
      "text": "Elon Musk might merge SpaceX with Tesla or xAI",
      "url": "https://www.theverge.com/tech/870380/elon-musk-space-x-xai-merger"
    },
    {
      "text": "Apple’s second biggest acquisition ever is an AI company that listens to ‘silent speech’",
      "url": "https://www.theverge.com/news/870353/apple-q-ai-acquisition-silent-speech"
    },
    {
      "text": "Half of developers think gen AI is bad for the gaming industry",
      "url": "https://www.theverge.com/entertainment/869386/ai-game-development-gdc-survey"
    },
    {
      "text": "GOOGLE’S AI HELPED ME MAKE BAD NINTENDO KNOCKOFFS",
      "url": "https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on"
    }
  ],
  "lastUpdated": "2026-01-31T04:31:26Z"
}