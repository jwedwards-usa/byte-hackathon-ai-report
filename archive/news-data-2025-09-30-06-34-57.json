{
  "mainHeadline": {
    "text": "FORMALIZATION DRIVEN LLM PROMPT JAILBREAKING VIA REINFORCEMENT LEARNING",
    "url": "https://arxiv.org/abs/2509.23558"
  },
  "topStories": [
    {
      "text": "OpenAI’s ChatGPT parental controls are rolling out — here’s what you should know",
      "url": "https://www.theverge.com/ai-artificial-intelligence/787227/openais-parental-controls-are-out-heres-what-you-should-know"
    },
    {
      "text": "From Human Annotation to Automation: LLM-in-the-Loop Active Learning for Arabic Sentiment Analysis",
      "url": "https://arxiv.org/abs/2509.23515"
    },
    {
      "text": "Efficient Fine-Grained GPU Performance Modeling for Distributed Deep Learning of LLM",
      "url": "https://arxiv.org/abs/2509.22832"
    }
  ],
  "leftColumn": [
    {
      "text": "AI Brown and AI Koditex: LLM-Generated Corpora Comparable to Traditional Corpora of English and Czech Texts",
      "url": "https://arxiv.org/abs/2509.22996"
    },
    {
      "text": "BEYOND JAILBREAKING: AUDITING CONTEXTUAL PRIVACY IN LLM AGENTS",
      "url": "https://arxiv.org/abs/2506.10171"
    },
    {
      "text": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance",
      "url": "https://arxiv.org/abs/2410.22376"
    },
    {
      "text": "Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers",
      "url": "https://arxiv.org/abs/2509.22445"
    },
    {
      "text": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference",
      "url": "https://arxiv.org/abs/2505.09598"
    },
    {
      "text": "Machine Learning - Driven Materials Discovery: Unlocking Next-Generation Functional Materials - A review",
      "url": "https://arxiv.org/abs/2503.18975"
    },
    {
      "text": "Accuracy-Robustness Trade Off via Spiking Neural Network Gradient Sparsity Trail",
      "url": "https://arxiv.org/abs/2509.23762"
    },
    {
      "text": "The 2025 OpenAI Preparedness Framework does not guarantee any AI risk mitigation practices: a proof-of-concept for affordance analyses of AI safety policies",
      "url": "https://arxiv.org/abs/2509.24394"
    }
  ],
  "centerColumn": [
    {
      "text": "Double Descent as a Lens for Sample Efficiency in Autoregressive vs. Discrete Diffusion Models",
      "url": "https://arxiv.org/abs/2509.24974"
    },
    {
      "text": "LLM/Agent-as-Data-Analyst: A Survey",
      "url": "https://arxiv.org/abs/2509.23988"
    },
    {
      "text": "Intra-request branch orchestration for efficient LLM reasoning",
      "url": "https://arxiv.org/abs/2509.24957"
    },
    {
      "text": "Any-to-Bokeh: Arbitrary-Subject Video Refocusing with Video Diffusion Model",
      "url": "https://arxiv.org/abs/2505.21593"
    },
    {
      "text": "BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models",
      "url": "https://arxiv.org/abs/2505.16670"
    },
    {
      "text": "Reasoning Scaffolding: Distilling the Flow of Thought from LLMs",
      "url": "https://arxiv.org/abs/2509.23619"
    },
    {
      "text": "What SB 53, California’s new AI law, does",
      "url": "https://www.lesswrong.com/posts/z5wJMvTafuvBgHnEj/what-sb-53-california-s-new-ai-law-does"
    },
    {
      "text": "Reinforcement Mid-Training",
      "url": "https://arxiv.org/abs/2509.24375"
    }
  ],
  "rightColumn": [
    {
      "text": "Watermarking Diffusion Language Models",
      "url": "https://arxiv.org/abs/2509.24368"
    },
    {
      "text": "Expanding Horizons of Level Diversity via Multi-objective Evolutionary Learning",
      "url": "https://arxiv.org/abs/2509.24341"
    },
    {
      "text": "TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models",
      "url": "https://arxiv.org/abs/2509.24803"
    },
    {
      "text": "Towards Generalizable PDE Dynamics Forecasting via Physics-Guided Invariant Learning",
      "url": "https://arxiv.org/abs/2509.24332"
    },
    {
      "text": "Sotopia-RL: Reward Design for Social Intelligence",
      "url": "https://arxiv.org/abs/2508.03905"
    },
    {
      "text": "AuON: A Linear-time Alternative to Semi-Orthogonal Momentum Updates",
      "url": "https://arxiv.org/abs/2509.24320"
    },
    {
      "text": "CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders",
      "url": "https://arxiv.org/abs/2509.00691"
    },
    {
      "text": "Beyond Token Limits: Assessing Language Model Performance on Long Text Classification",
      "url": "https://arxiv.org/abs/2509.10199"
    }
  ],
  "lastUpdated": "2025-09-30T06:34:57Z"
}