{
  "mainHeadline": {
    "text": "Upwork study shows AI agents excel with human partners but fail independently",
    "url": "https://venturebeat.com/ai/upwork-study-shows-ai-agents-excel-with-human-partners-but-fail"
  },
  "topStories": [
    {
      "text": "OpenAI experiment finds that sparse models could give AI builders the tools to debug neural networks",
      "url": "https://venturebeat.com/ai/openai-experiment-finds-that-sparse-models-could-give-ai-builders-the-tools",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/5bjGX4CQLCQ6qGu7z6wGPu/02102d978305371822af26fa77648fa2/crimedy7_illustration_of_neural_networks_vivd_colors_--ar_169_31fd5a88-c680-439c-9d2b-e88d0ceeae89_2.png?w=300\u0026q=30",
        "alt": "OpenAI experiment finds that sparse models could give AI builders the tools to debug neural networks",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "CHATGPT GROUP CHATS ARE HERE … BUT NOT FOR EVERYONE (YET)",
      "url": "https://venturebeat.com/ai/chatgpt-group-chats-are-here-but-not-for-everyone-yet",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/4lD8xHoLueH39q7LYaoY0X/d121a8f4d69e53cb4ed2e6894726b7fb/gYge-sBdNYW1QP2kJADr-.png?w=300\u0026q=30",
        "alt": "ChatGPT Group Chats are here … but not for everyone (yet)",
        "width": 600,
        "height": 400
      }
    },
    {
      "text": "Baidu unveils proprietary ERNIE 5 beating GPT-5 performance on charts, document understanding and more",
      "url": "https://venturebeat.com/ai/baidu-unveils-proprietary-ernie-5-beating-gpt-5-performance-on-charts",
      "image": {
        "src": "https://images.ctfassets.net/jdtwqhzvc2n1/7tpZTCavJ5IcG1LDI66Xae/5066d5c70ead90c2f63e0ef888b9a9ef/YPf93J54wCLeSJI7yvPQK.png?w=300\u0026q=30",
        "alt": "Baidu unveils proprietary ERNIE 5 beating GPT-5 performance on charts, document understanding and more",
        "width": 600,
        "height": 400
      }
    }
  ],
  "leftColumn": [
    {
      "text": "OpenAI’s new LLM exposes the secrets of how AI really works",
      "url": "https://www.technologyreview.com/2025/11/13/1127914/openais-new-llm-exposes-the-secrets-of-how-ai-really-works/"
    },
    {
      "text": "Will AI systems drift into misalignment?",
      "url": "https://www.alignmentforum.org/posts/u8TYRhGPD878i3qkc/will-ai-systems-drift-into-misalignment"
    },
    {
      "text": "IS CHATGPT AND OPENAI STEALING IDEAS?",
      "url": "https://medium.com/@klaudibregu/is-chatgpt-and-openai-stealing-ideas-does-it-have-the-right-to-do-so-how-do-we-know-it-doesnt-c56faa33292f"
    },
    {
      "text": "AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics",
      "url": "https://arxiv.org/abs/2511.09785"
    },
    {
      "text": "How Anthropic's AI was jailbroken to become a weapon",
      "url": "https://venturebeat.com/security/how-anthropics-ai-was-jailbroken-to-become-a-weapon"
    },
    {
      "text": "Nano Banana can be prompt engineered for extremely nuanced AI image generation",
      "url": "https://simonwillison.net/2025/Nov/13/nano-banana-can-be-prompt-engineered/#atom-everything"
    },
    {
      "text": "I Measured Neural Network Training Every 5 Steps for 10,000 Iterations",
      "url": "https://towardsdatascience.com/i-measured-neural-network-training-every-5-steps-for-10000-iterations/"
    },
    {
      "text": "The Prompt War: How AI Decides on a Military Intervention",
      "url": "https://arxiv.org/abs/2507.06277"
    }
  ],
  "centerColumn": [
    {
      "text": "Same cognitive paints, exceedingly different mental pictures",
      "url": "https://www.lesswrong.com/posts/gEEcrYBFsjfgyYX8S/same-cognitive-paints-exceedingly-different-mental-pictures"
    },
    {
      "text": "HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization",
      "url": "https://arxiv.org/abs/2511.09578"
    },
    {
      "text": "Proceedings of The third international workshop on eXplainable AI for the Arts (XAIxArts)",
      "url": "https://arxiv.org/abs/2511.10482"
    },
    {
      "text": "Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search",
      "url": "https://arxiv.org/abs/2508.12211"
    },
    {
      "text": "Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware",
      "url": "https://arxiv.org/abs/2511.10277"
    },
    {
      "text": "Collapse of Irrelevant Representations (CIR) Ensures Robust and Non-Disruptive LLM Unlearning",
      "url": "https://arxiv.org/abs/2509.11816"
    },
    {
      "text": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption",
      "url": "https://arxiv.org/abs/2506.12846"
    },
    {
      "text": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm",
      "url": "https://arxiv.org/abs/2511.09392"
    }
  ],
  "rightColumn": [
    {
      "text": "MMTEB: Massive Multilingual Text Embedding Benchmark",
      "url": "https://arxiv.org/abs/2502.13595"
    },
    {
      "text": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models",
      "url": "https://arxiv.org/abs/2502.18573"
    },
    {
      "text": "SITA: A Framework for Structure-to-Instance Theorem Autoformalization",
      "url": "https://arxiv.org/abs/2511.10356"
    },
    {
      "text": "Feature-EndoGaussian: Feature Distilled Gaussian Splatting in Surgical Deformable Scene Reconstruction",
      "url": "https://arxiv.org/abs/2503.06161"
    },
    {
      "text": "ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs",
      "url": "https://arxiv.org/abs/2511.10240"
    },
    {
      "text": "Expandable and Differentiable Dual Memories with Orthogonal Regularization for Exemplar-free Continual Learning",
      "url": "https://arxiv.org/abs/2511.09871"
    },
    {
      "text": "One-Shot Multi-Label Causal Discovery in High-Dimensional Event Sequences",
      "url": "https://arxiv.org/abs/2509.23213"
    },
    {
      "text": "T2IBias: Uncovering Societal Bias Encoded in the Latent Space of Text-to-Image Generative Models",
      "url": "https://arxiv.org/abs/2511.10089"
    }
  ],
  "lastUpdated": "2025-11-15T15:23:10Z"
}